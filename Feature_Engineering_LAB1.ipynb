{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dinuka-Thathsara/04-Apr-2022-DevOps__Scan-Images-In-ACR-Using-Trivy/blob/main/Feature_Engineering_LAB1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Needed Packages"
      ],
      "metadata": {
        "id": "FOEvOc0cXBlm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2C8XGHdJx13"
      },
      "outputs": [],
      "source": [
        "## Data Analysis Phase\n",
        "## MAin aim is to understand more about the data\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "## Display all the columns of the dataframe\n",
        "\n",
        "pd.pandas.set_option('display.max_columns',None)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Uploading Datasets"
      ],
      "metadata": {
        "id": "8Uv8r8y6YJid"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6D_Bepp1-8XJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12e4f836-6728-41d4-e1c0-c6e7725a936f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28520, 260)\n",
            "(750, 260)\n",
            "(750, 260)\n"
          ]
        }
      ],
      "source": [
        "train_dataset=pd.read_csv('train.csv')\n",
        "valid_dataset=pd.read_csv('valid.csv')\n",
        "test_dataset=pd.read_csv('test.csv')\n",
        "## print shape of dataset with rows and columns\n",
        "print(train_dataset.shape)\n",
        "print(valid_dataset.shape)\n",
        "print(test_dataset.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "m-DqzECk_KU8",
        "outputId": "22890488-d50e-4f89-e79e-a69aed1edaa4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
              "0  -1.153148  -1.038098   1.419872   2.734152   1.154604  -1.086937   \n",
              "1  -1.377524  -1.018393   1.102352   2.849025   0.440302  -1.149039   \n",
              "2   0.889574  -2.743300  -0.320194   3.047766  -0.923335   1.741686   \n",
              "3  -1.527213  -1.133121   0.385927   3.129767   0.229020   1.373105   \n",
              "4   0.948176  -0.750248   0.008329   1.675338   1.941155  -0.783623   \n",
              "\n",
              "   feature_7  feature_8  feature_9  feature_10  feature_11  feature_12  \\\n",
              "0  -0.516225  -1.370325   2.865359   -1.879877   -1.409379    0.320105   \n",
              "1  -0.789796  -2.258196   1.264268   -2.123730   -1.480036   -0.370814   \n",
              "2  -0.615148   0.756482   2.074775   -1.433126   -0.068064    0.598540   \n",
              "3   0.919284  -0.755558   1.086973   -2.440614   -0.565188   -1.627237   \n",
              "4  -0.485584  -0.261882   2.875204   -1.473030   -0.160699    0.289259   \n",
              "\n",
              "   feature_13  feature_14  feature_15  feature_16  feature_17  feature_18  \\\n",
              "0    1.704116    1.655839    1.251337   -2.723541   -0.641919   -4.206987   \n",
              "1    1.337393    1.043868    1.037037   -2.572335    0.575396   -4.482491   \n",
              "2    1.747028    0.308814    1.438595   -2.713891   -1.504777   -4.458522   \n",
              "3    1.396390    1.128513   -0.493460   -0.038711    0.602175   -3.371845   \n",
              "4    2.305159   -0.126328   -0.222299   -2.617932   -0.619935   -4.951178   \n",
              "\n",
              "   feature_19  feature_20  feature_21  feature_22  feature_23  feature_24  \\\n",
              "0   -0.263210    0.194837   -2.158549    1.086174    0.501373   -1.598422   \n",
              "1   -1.034487    0.437354   -2.521748    1.507435   -0.274363   -3.431944   \n",
              "2    0.155936    0.417320   -4.085610    1.279542    0.348400   -0.366978   \n",
              "3   -2.498516    2.503236   -2.435895    0.942354    0.043507   -2.201002   \n",
              "4   -0.346735    1.704095   -3.009544    0.741036    0.611817   -2.723161   \n",
              "\n",
              "   feature_25  feature_26  feature_27  feature_28  feature_29  feature_30  \\\n",
              "0   -1.976589    3.457837   -0.976514    0.201892   -0.226071   -0.410385   \n",
              "1   -1.560407    4.324077   -2.342700   -0.335287   -0.538335   -0.083395   \n",
              "2   -2.583359    2.598797    0.575795    0.082680   -0.442469   -0.837585   \n",
              "3   -0.735961    3.204553   -1.264879    0.635861   -3.064966   -2.655011   \n",
              "4   -1.415860    1.361665   -1.888240    1.091696   -0.375257   -1.554744   \n",
              "\n",
              "   feature_31  feature_32  feature_33  feature_34  feature_35  feature_36  \\\n",
              "0   -1.571100    2.592908   -1.291827   -0.366841   -0.410952    1.015914   \n",
              "1   -1.408175    2.230254    0.767140    0.320735   -1.722289    2.086905   \n",
              "2   -0.474353    0.484577   -2.375412    1.408367   -0.847942    0.744728   \n",
              "3   -0.296643    2.477197   -1.534483   -1.056755   -0.100055    1.764300   \n",
              "4   -0.669312    2.200294   -0.712490    2.395652    0.465258    3.061924   \n",
              "\n",
              "   feature_37  feature_38  feature_39  feature_40  feature_41  feature_42  \\\n",
              "0   -1.904730    0.709462    0.591671    0.643340   -0.228592    0.556915   \n",
              "1   -0.732669    0.833688    0.766325    1.289876    0.870834    1.620561   \n",
              "2    0.338863   -0.330735   -0.162522    0.452853    0.040784    0.636638   \n",
              "3    0.323443   -0.412691    0.305619   -0.170311    0.290808    0.765568   \n",
              "4   -1.661386    0.511598    1.307248    0.204698    1.896613    0.959890   \n",
              "\n",
              "   feature_43  feature_44  feature_45  feature_46  feature_47  feature_48  \\\n",
              "0   -0.645377   -3.040553   -1.637680    1.255634    1.715204   -0.688397   \n",
              "1   -0.413392   -3.004543   -1.575161    0.230717    0.709130    0.627740   \n",
              "2    0.488008   -2.807750   -0.646960    0.408045   -1.926035   -0.817600   \n",
              "3    0.568708   -2.309546   -0.082422   -0.406527   -0.130403   -1.042421   \n",
              "4    0.726368   -4.255481   -2.185033    0.425133    1.109373   -0.356726   \n",
              "\n",
              "   feature_49  feature_50  feature_51  feature_52  feature_53  feature_54  \\\n",
              "0    1.111274    0.497654   -1.042886    0.402539   -0.542546    1.105108   \n",
              "1    1.567949    0.177835   -1.004002    0.896508    0.442845    0.568543   \n",
              "2    1.965834    1.634271   -0.057730   -1.051165   -0.985080   -1.028156   \n",
              "3    1.668278    0.076061   -0.624170   -0.340301   -0.232693   -0.694077   \n",
              "4    0.777323    1.211375    0.702060    0.255479    0.439791   -1.058073   \n",
              "\n",
              "   feature_55  feature_56  feature_57  feature_58  feature_59  feature_60  \\\n",
              "0   -0.747230    0.383964   -2.010832    0.953861   -0.790129   -0.476429   \n",
              "1   -1.023931   -1.813623    0.091259   -0.295286   -0.550783   -0.718510   \n",
              "2   -2.506213   -0.687154    0.882658    3.042392    0.408750   -0.388141   \n",
              "3    0.120609   -0.181700   -1.227839    1.517968   -0.254498   -1.156026   \n",
              "4   -1.484549    0.925864    0.694274    2.415081    0.112275   -1.632634   \n",
              "\n",
              "   feature_61  feature_62  feature_63  feature_64  feature_65  feature_66  \\\n",
              "0   -1.070531   -1.575460   -1.174140    2.737756    1.564034    0.336269   \n",
              "1   -0.908675   -1.279681   -0.542199    2.746981    2.511886    0.305444   \n",
              "2    1.037253   -0.013801   -1.073934    2.696985    1.102886    1.107540   \n",
              "3    0.845028   -1.565275   -2.187371    2.092654   -0.277010    0.747036   \n",
              "4    0.566655   -0.339927   -1.295883    2.088299    2.267484   -0.299912   \n",
              "\n",
              "   feature_67  feature_68  feature_69  feature_70  feature_71  feature_72  \\\n",
              "0   -1.620437   -0.327836    0.249010   -0.284077   -1.151560   -0.180647   \n",
              "1   -1.991450   -0.180366   -0.398635   -0.093401   -0.818655   -2.229760   \n",
              "2   -1.580062    0.529930   -1.735664    2.087687   -1.865816   -1.085436   \n",
              "3   -2.091516    0.248123   -1.513840    1.145658    0.720055   -1.349451   \n",
              "4   -0.205782    1.263023   -1.989637    1.348971   -1.039191   -1.875184   \n",
              "\n",
              "   feature_73  feature_74  feature_75  feature_76  feature_77  feature_78  \\\n",
              "0   -0.453377   -1.388229    0.151455    0.905556    1.383817    2.559482   \n",
              "1   -0.420237   -0.177485    0.703523    1.320710    1.437858    2.810093   \n",
              "2    2.077800    2.181563    0.676282    1.537059    0.437179    3.207828   \n",
              "3    0.580730   -0.639348    0.919229   -0.793818   -0.373706    4.089901   \n",
              "4    0.721441    0.294191    0.221436    0.792514   -0.752636    5.088836   \n",
              "\n",
              "   feature_79  feature_80  feature_81  feature_82  feature_83  feature_84  \\\n",
              "0   -3.119863   -0.791112   -1.569321   -1.430436   -1.514173    2.985236   \n",
              "1   -2.619601   -1.280195   -1.424652   -0.265742   -0.057746    3.022341   \n",
              "2   -0.948437    0.361401   -0.624320   -2.360142   -3.044507    0.900405   \n",
              "3   -0.264145   -1.705614   -0.755140    0.809717   -1.598379    3.160564   \n",
              "4    0.496678   -0.984859   -0.562585   -2.258661   -1.817895    2.861654   \n",
              "\n",
              "   feature_85  feature_86  feature_87  feature_88  feature_89  feature_90  \\\n",
              "0    0.580871   -0.764486   -0.260519    0.939849   -0.470598   -2.861254   \n",
              "1    1.991786    0.298979   -0.923647    2.248602   -0.455463   -2.657235   \n",
              "2    0.894809    1.611774   -0.082311    3.067043    0.781910   -3.374880   \n",
              "3    1.170041    1.224120   -0.914786    2.774773    0.408935   -1.848639   \n",
              "4    0.981906   -0.947889    0.441403    1.367464    0.099122   -4.565517   \n",
              "\n",
              "   feature_91  feature_92  feature_93  feature_94  feature_95  feature_96  \\\n",
              "0   -0.173464    2.016990    3.445552   -0.445339    1.212582    2.739672   \n",
              "1    0.873083    0.873754    3.172528   -0.686660    1.151290    2.640462   \n",
              "2    1.657745    2.621795    0.566249    1.616813    0.483428    2.613995   \n",
              "3    3.260644   -0.466688    1.058204    1.590415   -0.732783    3.119562   \n",
              "4    1.476906    0.694022    0.628808    1.002152    0.463058    2.210602   \n",
              "\n",
              "   feature_97  feature_98  feature_99  feature_100  feature_101  feature_102  \\\n",
              "0   -0.642328    1.219325    0.800850    -0.674323    -0.148795    -0.715005   \n",
              "1   -1.102167    0.235478    0.691108    -0.993033     0.267086    -0.978959   \n",
              "2    0.053810   -0.163222    1.368764     2.882331     1.319969    -0.076523   \n",
              "3    0.739683    1.613508    0.940187     2.606899    -0.622144     0.346026   \n",
              "4   -0.190344   -0.726012   -0.484766    -0.137692     0.954836     1.820612   \n",
              "\n",
              "   feature_103  feature_104  feature_105  feature_106  feature_107  \\\n",
              "0     0.016303    -0.687293    -2.884114     2.097714    -0.420214   \n",
              "1    -0.953110    -0.689617    -3.195319     1.675777     0.991395   \n",
              "2     0.292585     0.424204    -3.125484     4.271754     0.003506   \n",
              "3    -1.391296     1.045245    -2.003494     4.174849    -0.889034   \n",
              "4    -1.137770     0.878297    -2.351335     2.699015    -0.645027   \n",
              "\n",
              "   feature_108  feature_109  feature_110  feature_111  feature_112  \\\n",
              "0     3.279095     0.215530     0.222900    -2.023197     0.508495   \n",
              "1     2.254699     1.935017     0.434932    -1.676521     0.700489   \n",
              "2     2.165426     2.216364     1.274847    -2.215402     2.470454   \n",
              "3     2.308643     1.999224     2.193147    -3.366686     0.717010   \n",
              "4     3.779342     0.871177     1.013069    -2.018157     0.833605   \n",
              "\n",
              "   feature_113  feature_114  feature_115  feature_116  feature_117  \\\n",
              "0    -1.153753    -1.204272     1.298655     0.307644    -0.471440   \n",
              "1    -1.825381    -0.678953     0.933151    -0.501178     0.847771   \n",
              "2    -2.996966    -1.834035    -0.470077    -0.512093    -1.698522   \n",
              "3    -1.075971     0.606645     1.389568    -0.699702     0.320103   \n",
              "4    -3.071455    -1.480018     0.664669    -0.201570    -0.583158   \n",
              "\n",
              "   feature_118  feature_119  feature_120  feature_121  feature_122  \\\n",
              "0    -0.059421    -0.163380     0.395338    -0.169793     0.409149   \n",
              "1     0.895918    -2.489937     0.148797     0.283701     0.977651   \n",
              "2     1.150141    -1.353543     2.651054     1.000973     3.791727   \n",
              "3     0.402176    -0.800103     1.534205     0.774308     0.487083   \n",
              "4    -1.364045    -2.453391     0.240503     0.186601     1.818926   \n",
              "\n",
              "   feature_123  feature_124  feature_125  feature_126  feature_127  \\\n",
              "0    -0.636991    -1.031353     1.047208     0.192124    -1.488775   \n",
              "1    -0.333899    -1.185957     0.497641    -0.777000    -1.134971   \n",
              "2     0.927324     2.259706     0.299818    -0.181001    -2.243796   \n",
              "3     0.152025     1.375199    -1.602308    -0.341696    -1.842209   \n",
              "4    -0.742571    -0.037177     1.280065     0.518486    -1.779763   \n",
              "\n",
              "   feature_128  feature_129  feature_130  feature_131  feature_132  \\\n",
              "0     0.114282    -1.130616     0.270472     3.699157     2.386589   \n",
              "1    -0.043783    -0.025386    -1.949964     2.903008     1.767356   \n",
              "2     2.582069     2.752008    -3.786018     1.871401     1.600301   \n",
              "3     1.203861     0.353427    -2.607541     4.440294     2.010852   \n",
              "4     0.429643     0.878478    -1.078574     3.409653     1.151645   \n",
              "\n",
              "   feature_133  feature_134  feature_135  feature_136  feature_137  \\\n",
              "0    -1.505676     1.443920     0.117905     0.131196     2.392816   \n",
              "1    -1.890247     2.130077     1.575148    -0.008119     3.133822   \n",
              "2    -3.499447     0.890145     3.201261    -0.732026     2.355211   \n",
              "3    -0.234556     1.379486     3.946222    -0.057069     2.892920   \n",
              "4    -2.423276     2.432567     1.464046     0.792889     1.594565   \n",
              "\n",
              "   feature_138  feature_139  feature_140  feature_141  feature_142  \\\n",
              "0     1.464536     1.275852    -1.290619     1.623029    -1.412011   \n",
              "1     0.367785     1.608083    -0.738364     1.252715    -1.298761   \n",
              "2    -1.167341     0.308718     1.244494     2.741512    -1.443089   \n",
              "3     0.206937    -0.017862    -1.035440     1.826345    -1.320592   \n",
              "4     0.362187     0.413490     0.325162     1.090187    -3.228460   \n",
              "\n",
              "   feature_143  feature_144  feature_145  feature_146  feature_147  \\\n",
              "0     0.205905     2.301734     1.675485     0.759220     1.691173   \n",
              "1     0.438147     0.505633     0.907046     0.426572     1.318294   \n",
              "2     1.920954     1.407865    -0.812475     0.641355    -1.667917   \n",
              "3     1.831217     0.570368     0.975892    -1.335703    -0.108493   \n",
              "4     0.707163     1.954086     0.877493     1.466568    -0.396870   \n",
              "\n",
              "   feature_148  feature_149  feature_150  feature_151  feature_152  \\\n",
              "0     0.931612     0.439806    -0.146381    -1.327191    -1.345457   \n",
              "1     0.773356    -0.013219    -0.044907    -1.144436     0.913065   \n",
              "2     0.403139    -0.627385    -2.674358     0.084885    -0.538724   \n",
              "3     0.178833    -0.060930     0.022329     0.501405    -0.963698   \n",
              "4     1.685474    -0.330427    -0.978125    -0.687624    -0.895253   \n",
              "\n",
              "   feature_153  feature_154  feature_155  feature_156  feature_157  \\\n",
              "0    -0.181773    -0.360018    -1.173974    -1.003600     0.633813   \n",
              "1    -0.714127    -1.729165    -0.020797    -0.557447     1.587982   \n",
              "2    -0.972709    -1.782716     1.740537    -0.204722    -1.108238   \n",
              "3    -0.611106     0.011987     1.349425    -0.327173     0.196352   \n",
              "4    -0.444210    -0.605341    -1.032263    -0.666210    -0.301659   \n",
              "\n",
              "   feature_158  feature_159  feature_160  feature_161  feature_162  \\\n",
              "0    -1.036293    -0.649959     0.881835    -2.622058     1.210781   \n",
              "1    -2.157808    -1.205578     2.327618    -1.701403     1.248531   \n",
              "2    -2.753174     0.128128     2.109432    -0.431198    -0.746089   \n",
              "3    -2.444371    -0.828266     1.982651    -0.822506     1.120825   \n",
              "4    -2.534818     0.324984     0.993940     0.535053    -0.874236   \n",
              "\n",
              "   feature_163  feature_164  feature_165  feature_166  feature_167  \\\n",
              "0    -1.647564     2.239728    -0.443698     0.008438     2.502906   \n",
              "1    -2.182585     1.814523     0.075408    -1.357059     1.987957   \n",
              "2    -1.905429     2.762295    -2.902401     0.157960     0.131560   \n",
              "3    -0.263532     1.384485    -1.324554    -1.652047     2.036757   \n",
              "4    -1.659583     2.242578    -0.775007    -0.137154     1.877279   \n",
              "\n",
              "   feature_168  feature_169  feature_170  feature_171  feature_172  \\\n",
              "0     0.347715    -0.337608    -1.512681    -1.112664     2.003638   \n",
              "1    -0.213262    -1.066381    -1.749353    -1.179543     2.229092   \n",
              "2     0.846749    -0.749586    -3.943792    -0.819606     1.675375   \n",
              "3     0.884038    -0.073252    -3.039382    -1.048928     1.850740   \n",
              "4    -0.892328    -0.911374    -2.287852    -1.846204     0.974298   \n",
              "\n",
              "   feature_173  feature_174  feature_175  feature_176  feature_177  \\\n",
              "0    -0.831244    -0.339829     1.455606     1.992911    -1.099447   \n",
              "1    -1.711803     0.469646     1.162583     2.181157    -1.407149   \n",
              "2    -2.978254     1.972330    -0.681611     1.101892     2.447925   \n",
              "3    -1.708344     0.239440    -0.432976     1.396593     2.401515   \n",
              "4    -1.766163    -0.013610     0.904179     0.108735    -0.103769   \n",
              "\n",
              "   feature_178  feature_179  feature_180  feature_181  feature_182  \\\n",
              "0     2.584032     2.039423    -0.645410     0.495904     1.120493   \n",
              "1     2.457415     0.694950    -0.728181     1.278901     1.337580   \n",
              "2     1.333436     0.530785    -1.137186     0.758588     0.565381   \n",
              "3     1.437454    -0.097905    -0.054642     0.111235     2.007907   \n",
              "4     1.152863    -0.736740    -3.496263     0.802070    -0.375151   \n",
              "\n",
              "   feature_183  feature_184  feature_185  feature_186  feature_187  \\\n",
              "0     0.265891     1.469184     0.354903     2.699039     0.795559   \n",
              "1     0.184999     1.624231    -1.367010     2.136319     1.370169   \n",
              "2    -0.253345     1.268174    -2.279669     0.942738     2.148296   \n",
              "3    -0.104267     0.837830    -2.229129     1.292541     1.866845   \n",
              "4    -3.010861     1.026657    -0.218227     2.181341     0.940091   \n",
              "\n",
              "   feature_188  feature_189  feature_190  feature_191  feature_192  \\\n",
              "0    -1.527786    -0.215560    -2.149352    -0.513376     0.842640   \n",
              "1    -1.095014    -2.382134    -1.737152     0.044933     0.746034   \n",
              "2     0.781780    -1.431568    -2.320069    -0.521101     1.436933   \n",
              "3     1.043962    -1.218874    -1.378514    -0.957665     2.771368   \n",
              "4     0.462749    -0.498019    -3.216477    -0.724057     1.795768   \n",
              "\n",
              "   feature_193  feature_194  feature_195  feature_196  feature_197  \\\n",
              "0     3.554728     1.527833    -1.556303    -0.587206     1.662382   \n",
              "1     1.877104     1.332648    -0.199040     0.101963     1.495080   \n",
              "2     0.612523     0.770629    -0.497572     0.425608    -1.119316   \n",
              "3     2.257250     1.245677    -2.075094     2.186147    -0.314110   \n",
              "4     1.609647     0.879645    -0.619501     0.251506    -1.245882   \n",
              "\n",
              "   feature_198  feature_199  feature_200  feature_201  feature_202  \\\n",
              "0    -0.714246     1.186730    -0.145115     0.295924    -0.532481   \n",
              "1    -1.017038     0.186521    -1.309609     0.472736    -0.861389   \n",
              "2    -0.393558     1.740232    -2.451356     2.294403     2.709764   \n",
              "3    -1.259806     0.409803    -1.699620     0.186563    -0.758017   \n",
              "4    -0.059462     0.382695    -1.949562     1.221119     2.630744   \n",
              "\n",
              "   feature_203  feature_204  feature_205  feature_206  feature_207  \\\n",
              "0    -1.896905    -1.239928    -3.666890    -0.901890     1.588130   \n",
              "1    -1.989814    -0.465665    -3.516261    -0.593888     1.215666   \n",
              "2    -2.017183    -0.235833    -2.430242     1.457975    -0.622639   \n",
              "3     0.871980    -0.486622    -2.341567     0.897780    -0.065674   \n",
              "4    -0.233323    -0.066793    -2.093198     0.781117    -0.230964   \n",
              "\n",
              "   feature_208  feature_209  feature_210  feature_211  feature_212  \\\n",
              "0     0.142595     1.254227     1.221567    -2.866955    -1.190926   \n",
              "1    -0.459955     0.721586     1.316415    -3.599638    -1.353255   \n",
              "2     1.224396     1.235596     1.519492    -0.524034    -1.654578   \n",
              "3     1.860209     1.643175     0.045659    -2.051654    -0.683399   \n",
              "4     0.694065     1.086709     0.793822    -1.910584    -1.488135   \n",
              "\n",
              "   feature_213  feature_214  feature_215  feature_216  feature_217  \\\n",
              "0    -1.076426     1.899313    -0.574136     1.902088    -3.170757   \n",
              "1    -2.604110     2.856650    -0.800402     1.819534    -3.557524   \n",
              "2    -2.101801    -0.941467    -1.796806     2.479564    -0.038002   \n",
              "3    -0.542855     0.725036    -2.858389     2.773426    -1.226120   \n",
              "4     0.329182     3.073059    -0.513672    -0.266794    -0.925509   \n",
              "\n",
              "   feature_218  feature_219  feature_220  feature_221  feature_222  \\\n",
              "0    -1.927889    -0.800191     1.404616     0.833011    -1.435146   \n",
              "1    -0.337203    -0.608348     1.265913     0.661117    -2.093112   \n",
              "2    -3.641708    -0.018166     3.271545     0.378753    -0.108741   \n",
              "3    -2.527034     0.747429     1.975456     0.500852    -0.860470   \n",
              "4    -3.195087    -0.426922     1.637993     1.364704     0.528615   \n",
              "\n",
              "   feature_223  feature_224  feature_225  feature_226  feature_227  \\\n",
              "0    -0.669946    -0.628177    -2.242126    -0.026335     1.311732   \n",
              "1    -0.760502     0.471058    -0.604653    -0.017820     1.238391   \n",
              "2    -2.073370    -2.594663    -0.569902    -2.202442     1.376741   \n",
              "3    -0.675475     0.340702     0.500773    -0.627366    -0.645546   \n",
              "4    -0.684009    -0.323255    -1.894410    -0.988054     1.570205   \n",
              "\n",
              "   feature_228  feature_229  feature_230  feature_231  feature_232  \\\n",
              "0     0.180004     0.024092    -1.461941    -1.563753     3.114331   \n",
              "1     1.020576    -0.097181    -2.133749    -0.895949     1.529343   \n",
              "2    -0.607759     2.355708    -3.633044     0.252401     1.554519   \n",
              "3    -0.463846     2.623931    -1.914251     0.088570     1.994985   \n",
              "4    -1.842084     1.099123    -1.361982     0.285133     2.951020   \n",
              "\n",
              "   feature_233  feature_234  feature_235  feature_236  feature_237  \\\n",
              "0    -0.489507    -0.035621    -0.351813    -1.816677    -0.974662   \n",
              "1     0.231963     1.697689    -0.519540    -2.491656    -0.655185   \n",
              "2     0.908245     0.548797    -2.824641    -1.486418     1.806167   \n",
              "3     1.659639     1.896314    -0.711247    -2.300663     1.871941   \n",
              "4     1.548886     0.000797    -0.820848    -0.469899     0.312798   \n",
              "\n",
              "   feature_238  feature_239  feature_240  feature_241  feature_242  \\\n",
              "0     2.148677    -0.780091     0.450283     0.785037    -1.283915   \n",
              "1     1.620014    -0.845751     0.494454    -0.271467    -1.795943   \n",
              "2     1.680712     0.691597     1.551380     0.683709     0.983895   \n",
              "3     0.919648    -0.882903     0.966500     0.635516    -0.666670   \n",
              "4    -0.188478     0.567227     0.456920     0.230514    -1.348908   \n",
              "\n",
              "   feature_243  feature_244  feature_245  feature_246  feature_247  \\\n",
              "0     0.593244     1.686675     1.344741     1.188726     3.051455   \n",
              "1     0.440410     3.982734     0.319849     1.118826     1.343224   \n",
              "2     0.019876     0.513138    -0.852068     0.368997     3.139382   \n",
              "3    -0.847318     0.675496     1.160198    -1.155169     0.029133   \n",
              "4    -1.371241     1.603917     0.299558    -1.909181    -0.295354   \n",
              "\n",
              "   feature_248  feature_249  feature_250  feature_251  feature_252  \\\n",
              "0    -1.061046     0.382224     0.076990    -0.719046    -1.248530   \n",
              "1     0.120304    -0.066218    -0.231481    -1.383339    -0.787736   \n",
              "2    -1.166126    -1.299070    -2.486144     1.178322     0.035333   \n",
              "3    -1.663985    -0.865878    -1.387906    -0.664176     0.805059   \n",
              "4     0.061812    -0.368456     0.344975    -0.665200    -0.428060   \n",
              "\n",
              "   feature_253  feature_254  feature_255  feature_256  label_1  label_2  \\\n",
              "0     0.144460    -3.240056     0.052614     0.083108       45      NaN   \n",
              "1     1.044895    -2.289637     0.199752    -0.712154       45      NaN   \n",
              "2     0.857712    -1.928684     0.639870    -0.268576       45      NaN   \n",
              "3     0.975368    -2.700269     1.523236    -1.259052       45      NaN   \n",
              "4    -0.393100    -1.854657     2.207063    -0.342725       45      NaN   \n",
              "\n",
              "   label_3  label_4  \n",
              "0        1        6  \n",
              "1        1        6  \n",
              "2        1        6  \n",
              "3        1        6  \n",
              "4        1        6  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-36993fec-5f79-43c0-bfe5-2b1e5eace78b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_1</th>\n",
              "      <th>feature_2</th>\n",
              "      <th>feature_3</th>\n",
              "      <th>feature_4</th>\n",
              "      <th>feature_5</th>\n",
              "      <th>feature_6</th>\n",
              "      <th>feature_7</th>\n",
              "      <th>feature_8</th>\n",
              "      <th>feature_9</th>\n",
              "      <th>feature_10</th>\n",
              "      <th>feature_11</th>\n",
              "      <th>feature_12</th>\n",
              "      <th>feature_13</th>\n",
              "      <th>feature_14</th>\n",
              "      <th>feature_15</th>\n",
              "      <th>feature_16</th>\n",
              "      <th>feature_17</th>\n",
              "      <th>feature_18</th>\n",
              "      <th>feature_19</th>\n",
              "      <th>feature_20</th>\n",
              "      <th>feature_21</th>\n",
              "      <th>feature_22</th>\n",
              "      <th>feature_23</th>\n",
              "      <th>feature_24</th>\n",
              "      <th>feature_25</th>\n",
              "      <th>feature_26</th>\n",
              "      <th>feature_27</th>\n",
              "      <th>feature_28</th>\n",
              "      <th>feature_29</th>\n",
              "      <th>feature_30</th>\n",
              "      <th>feature_31</th>\n",
              "      <th>feature_32</th>\n",
              "      <th>feature_33</th>\n",
              "      <th>feature_34</th>\n",
              "      <th>feature_35</th>\n",
              "      <th>feature_36</th>\n",
              "      <th>feature_37</th>\n",
              "      <th>feature_38</th>\n",
              "      <th>feature_39</th>\n",
              "      <th>feature_40</th>\n",
              "      <th>feature_41</th>\n",
              "      <th>feature_42</th>\n",
              "      <th>feature_43</th>\n",
              "      <th>feature_44</th>\n",
              "      <th>feature_45</th>\n",
              "      <th>feature_46</th>\n",
              "      <th>feature_47</th>\n",
              "      <th>feature_48</th>\n",
              "      <th>feature_49</th>\n",
              "      <th>feature_50</th>\n",
              "      <th>feature_51</th>\n",
              "      <th>feature_52</th>\n",
              "      <th>feature_53</th>\n",
              "      <th>feature_54</th>\n",
              "      <th>feature_55</th>\n",
              "      <th>feature_56</th>\n",
              "      <th>feature_57</th>\n",
              "      <th>feature_58</th>\n",
              "      <th>feature_59</th>\n",
              "      <th>feature_60</th>\n",
              "      <th>feature_61</th>\n",
              "      <th>feature_62</th>\n",
              "      <th>feature_63</th>\n",
              "      <th>feature_64</th>\n",
              "      <th>feature_65</th>\n",
              "      <th>feature_66</th>\n",
              "      <th>feature_67</th>\n",
              "      <th>feature_68</th>\n",
              "      <th>feature_69</th>\n",
              "      <th>feature_70</th>\n",
              "      <th>feature_71</th>\n",
              "      <th>feature_72</th>\n",
              "      <th>feature_73</th>\n",
              "      <th>feature_74</th>\n",
              "      <th>feature_75</th>\n",
              "      <th>feature_76</th>\n",
              "      <th>feature_77</th>\n",
              "      <th>feature_78</th>\n",
              "      <th>feature_79</th>\n",
              "      <th>feature_80</th>\n",
              "      <th>feature_81</th>\n",
              "      <th>feature_82</th>\n",
              "      <th>feature_83</th>\n",
              "      <th>feature_84</th>\n",
              "      <th>feature_85</th>\n",
              "      <th>feature_86</th>\n",
              "      <th>feature_87</th>\n",
              "      <th>feature_88</th>\n",
              "      <th>feature_89</th>\n",
              "      <th>feature_90</th>\n",
              "      <th>feature_91</th>\n",
              "      <th>feature_92</th>\n",
              "      <th>feature_93</th>\n",
              "      <th>feature_94</th>\n",
              "      <th>feature_95</th>\n",
              "      <th>feature_96</th>\n",
              "      <th>feature_97</th>\n",
              "      <th>feature_98</th>\n",
              "      <th>feature_99</th>\n",
              "      <th>feature_100</th>\n",
              "      <th>feature_101</th>\n",
              "      <th>feature_102</th>\n",
              "      <th>feature_103</th>\n",
              "      <th>feature_104</th>\n",
              "      <th>feature_105</th>\n",
              "      <th>feature_106</th>\n",
              "      <th>feature_107</th>\n",
              "      <th>feature_108</th>\n",
              "      <th>feature_109</th>\n",
              "      <th>feature_110</th>\n",
              "      <th>feature_111</th>\n",
              "      <th>feature_112</th>\n",
              "      <th>feature_113</th>\n",
              "      <th>feature_114</th>\n",
              "      <th>feature_115</th>\n",
              "      <th>feature_116</th>\n",
              "      <th>feature_117</th>\n",
              "      <th>feature_118</th>\n",
              "      <th>feature_119</th>\n",
              "      <th>feature_120</th>\n",
              "      <th>feature_121</th>\n",
              "      <th>feature_122</th>\n",
              "      <th>feature_123</th>\n",
              "      <th>feature_124</th>\n",
              "      <th>feature_125</th>\n",
              "      <th>feature_126</th>\n",
              "      <th>feature_127</th>\n",
              "      <th>feature_128</th>\n",
              "      <th>feature_129</th>\n",
              "      <th>feature_130</th>\n",
              "      <th>feature_131</th>\n",
              "      <th>feature_132</th>\n",
              "      <th>feature_133</th>\n",
              "      <th>feature_134</th>\n",
              "      <th>feature_135</th>\n",
              "      <th>feature_136</th>\n",
              "      <th>feature_137</th>\n",
              "      <th>feature_138</th>\n",
              "      <th>feature_139</th>\n",
              "      <th>feature_140</th>\n",
              "      <th>feature_141</th>\n",
              "      <th>feature_142</th>\n",
              "      <th>feature_143</th>\n",
              "      <th>feature_144</th>\n",
              "      <th>feature_145</th>\n",
              "      <th>feature_146</th>\n",
              "      <th>feature_147</th>\n",
              "      <th>feature_148</th>\n",
              "      <th>feature_149</th>\n",
              "      <th>feature_150</th>\n",
              "      <th>feature_151</th>\n",
              "      <th>feature_152</th>\n",
              "      <th>feature_153</th>\n",
              "      <th>feature_154</th>\n",
              "      <th>feature_155</th>\n",
              "      <th>feature_156</th>\n",
              "      <th>feature_157</th>\n",
              "      <th>feature_158</th>\n",
              "      <th>feature_159</th>\n",
              "      <th>feature_160</th>\n",
              "      <th>feature_161</th>\n",
              "      <th>feature_162</th>\n",
              "      <th>feature_163</th>\n",
              "      <th>feature_164</th>\n",
              "      <th>feature_165</th>\n",
              "      <th>feature_166</th>\n",
              "      <th>feature_167</th>\n",
              "      <th>feature_168</th>\n",
              "      <th>feature_169</th>\n",
              "      <th>feature_170</th>\n",
              "      <th>feature_171</th>\n",
              "      <th>feature_172</th>\n",
              "      <th>feature_173</th>\n",
              "      <th>feature_174</th>\n",
              "      <th>feature_175</th>\n",
              "      <th>feature_176</th>\n",
              "      <th>feature_177</th>\n",
              "      <th>feature_178</th>\n",
              "      <th>feature_179</th>\n",
              "      <th>feature_180</th>\n",
              "      <th>feature_181</th>\n",
              "      <th>feature_182</th>\n",
              "      <th>feature_183</th>\n",
              "      <th>feature_184</th>\n",
              "      <th>feature_185</th>\n",
              "      <th>feature_186</th>\n",
              "      <th>feature_187</th>\n",
              "      <th>feature_188</th>\n",
              "      <th>feature_189</th>\n",
              "      <th>feature_190</th>\n",
              "      <th>feature_191</th>\n",
              "      <th>feature_192</th>\n",
              "      <th>feature_193</th>\n",
              "      <th>feature_194</th>\n",
              "      <th>feature_195</th>\n",
              "      <th>feature_196</th>\n",
              "      <th>feature_197</th>\n",
              "      <th>feature_198</th>\n",
              "      <th>feature_199</th>\n",
              "      <th>feature_200</th>\n",
              "      <th>feature_201</th>\n",
              "      <th>feature_202</th>\n",
              "      <th>feature_203</th>\n",
              "      <th>feature_204</th>\n",
              "      <th>feature_205</th>\n",
              "      <th>feature_206</th>\n",
              "      <th>feature_207</th>\n",
              "      <th>feature_208</th>\n",
              "      <th>feature_209</th>\n",
              "      <th>feature_210</th>\n",
              "      <th>feature_211</th>\n",
              "      <th>feature_212</th>\n",
              "      <th>feature_213</th>\n",
              "      <th>feature_214</th>\n",
              "      <th>feature_215</th>\n",
              "      <th>feature_216</th>\n",
              "      <th>feature_217</th>\n",
              "      <th>feature_218</th>\n",
              "      <th>feature_219</th>\n",
              "      <th>feature_220</th>\n",
              "      <th>feature_221</th>\n",
              "      <th>feature_222</th>\n",
              "      <th>feature_223</th>\n",
              "      <th>feature_224</th>\n",
              "      <th>feature_225</th>\n",
              "      <th>feature_226</th>\n",
              "      <th>feature_227</th>\n",
              "      <th>feature_228</th>\n",
              "      <th>feature_229</th>\n",
              "      <th>feature_230</th>\n",
              "      <th>feature_231</th>\n",
              "      <th>feature_232</th>\n",
              "      <th>feature_233</th>\n",
              "      <th>feature_234</th>\n",
              "      <th>feature_235</th>\n",
              "      <th>feature_236</th>\n",
              "      <th>feature_237</th>\n",
              "      <th>feature_238</th>\n",
              "      <th>feature_239</th>\n",
              "      <th>feature_240</th>\n",
              "      <th>feature_241</th>\n",
              "      <th>feature_242</th>\n",
              "      <th>feature_243</th>\n",
              "      <th>feature_244</th>\n",
              "      <th>feature_245</th>\n",
              "      <th>feature_246</th>\n",
              "      <th>feature_247</th>\n",
              "      <th>feature_248</th>\n",
              "      <th>feature_249</th>\n",
              "      <th>feature_250</th>\n",
              "      <th>feature_251</th>\n",
              "      <th>feature_252</th>\n",
              "      <th>feature_253</th>\n",
              "      <th>feature_254</th>\n",
              "      <th>feature_255</th>\n",
              "      <th>feature_256</th>\n",
              "      <th>label_1</th>\n",
              "      <th>label_2</th>\n",
              "      <th>label_3</th>\n",
              "      <th>label_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.153148</td>\n",
              "      <td>-1.038098</td>\n",
              "      <td>1.419872</td>\n",
              "      <td>2.734152</td>\n",
              "      <td>1.154604</td>\n",
              "      <td>-1.086937</td>\n",
              "      <td>-0.516225</td>\n",
              "      <td>-1.370325</td>\n",
              "      <td>2.865359</td>\n",
              "      <td>-1.879877</td>\n",
              "      <td>-1.409379</td>\n",
              "      <td>0.320105</td>\n",
              "      <td>1.704116</td>\n",
              "      <td>1.655839</td>\n",
              "      <td>1.251337</td>\n",
              "      <td>-2.723541</td>\n",
              "      <td>-0.641919</td>\n",
              "      <td>-4.206987</td>\n",
              "      <td>-0.263210</td>\n",
              "      <td>0.194837</td>\n",
              "      <td>-2.158549</td>\n",
              "      <td>1.086174</td>\n",
              "      <td>0.501373</td>\n",
              "      <td>-1.598422</td>\n",
              "      <td>-1.976589</td>\n",
              "      <td>3.457837</td>\n",
              "      <td>-0.976514</td>\n",
              "      <td>0.201892</td>\n",
              "      <td>-0.226071</td>\n",
              "      <td>-0.410385</td>\n",
              "      <td>-1.571100</td>\n",
              "      <td>2.592908</td>\n",
              "      <td>-1.291827</td>\n",
              "      <td>-0.366841</td>\n",
              "      <td>-0.410952</td>\n",
              "      <td>1.015914</td>\n",
              "      <td>-1.904730</td>\n",
              "      <td>0.709462</td>\n",
              "      <td>0.591671</td>\n",
              "      <td>0.643340</td>\n",
              "      <td>-0.228592</td>\n",
              "      <td>0.556915</td>\n",
              "      <td>-0.645377</td>\n",
              "      <td>-3.040553</td>\n",
              "      <td>-1.637680</td>\n",
              "      <td>1.255634</td>\n",
              "      <td>1.715204</td>\n",
              "      <td>-0.688397</td>\n",
              "      <td>1.111274</td>\n",
              "      <td>0.497654</td>\n",
              "      <td>-1.042886</td>\n",
              "      <td>0.402539</td>\n",
              "      <td>-0.542546</td>\n",
              "      <td>1.105108</td>\n",
              "      <td>-0.747230</td>\n",
              "      <td>0.383964</td>\n",
              "      <td>-2.010832</td>\n",
              "      <td>0.953861</td>\n",
              "      <td>-0.790129</td>\n",
              "      <td>-0.476429</td>\n",
              "      <td>-1.070531</td>\n",
              "      <td>-1.575460</td>\n",
              "      <td>-1.174140</td>\n",
              "      <td>2.737756</td>\n",
              "      <td>1.564034</td>\n",
              "      <td>0.336269</td>\n",
              "      <td>-1.620437</td>\n",
              "      <td>-0.327836</td>\n",
              "      <td>0.249010</td>\n",
              "      <td>-0.284077</td>\n",
              "      <td>-1.151560</td>\n",
              "      <td>-0.180647</td>\n",
              "      <td>-0.453377</td>\n",
              "      <td>-1.388229</td>\n",
              "      <td>0.151455</td>\n",
              "      <td>0.905556</td>\n",
              "      <td>1.383817</td>\n",
              "      <td>2.559482</td>\n",
              "      <td>-3.119863</td>\n",
              "      <td>-0.791112</td>\n",
              "      <td>-1.569321</td>\n",
              "      <td>-1.430436</td>\n",
              "      <td>-1.514173</td>\n",
              "      <td>2.985236</td>\n",
              "      <td>0.580871</td>\n",
              "      <td>-0.764486</td>\n",
              "      <td>-0.260519</td>\n",
              "      <td>0.939849</td>\n",
              "      <td>-0.470598</td>\n",
              "      <td>-2.861254</td>\n",
              "      <td>-0.173464</td>\n",
              "      <td>2.016990</td>\n",
              "      <td>3.445552</td>\n",
              "      <td>-0.445339</td>\n",
              "      <td>1.212582</td>\n",
              "      <td>2.739672</td>\n",
              "      <td>-0.642328</td>\n",
              "      <td>1.219325</td>\n",
              "      <td>0.800850</td>\n",
              "      <td>-0.674323</td>\n",
              "      <td>-0.148795</td>\n",
              "      <td>-0.715005</td>\n",
              "      <td>0.016303</td>\n",
              "      <td>-0.687293</td>\n",
              "      <td>-2.884114</td>\n",
              "      <td>2.097714</td>\n",
              "      <td>-0.420214</td>\n",
              "      <td>3.279095</td>\n",
              "      <td>0.215530</td>\n",
              "      <td>0.222900</td>\n",
              "      <td>-2.023197</td>\n",
              "      <td>0.508495</td>\n",
              "      <td>-1.153753</td>\n",
              "      <td>-1.204272</td>\n",
              "      <td>1.298655</td>\n",
              "      <td>0.307644</td>\n",
              "      <td>-0.471440</td>\n",
              "      <td>-0.059421</td>\n",
              "      <td>-0.163380</td>\n",
              "      <td>0.395338</td>\n",
              "      <td>-0.169793</td>\n",
              "      <td>0.409149</td>\n",
              "      <td>-0.636991</td>\n",
              "      <td>-1.031353</td>\n",
              "      <td>1.047208</td>\n",
              "      <td>0.192124</td>\n",
              "      <td>-1.488775</td>\n",
              "      <td>0.114282</td>\n",
              "      <td>-1.130616</td>\n",
              "      <td>0.270472</td>\n",
              "      <td>3.699157</td>\n",
              "      <td>2.386589</td>\n",
              "      <td>-1.505676</td>\n",
              "      <td>1.443920</td>\n",
              "      <td>0.117905</td>\n",
              "      <td>0.131196</td>\n",
              "      <td>2.392816</td>\n",
              "      <td>1.464536</td>\n",
              "      <td>1.275852</td>\n",
              "      <td>-1.290619</td>\n",
              "      <td>1.623029</td>\n",
              "      <td>-1.412011</td>\n",
              "      <td>0.205905</td>\n",
              "      <td>2.301734</td>\n",
              "      <td>1.675485</td>\n",
              "      <td>0.759220</td>\n",
              "      <td>1.691173</td>\n",
              "      <td>0.931612</td>\n",
              "      <td>0.439806</td>\n",
              "      <td>-0.146381</td>\n",
              "      <td>-1.327191</td>\n",
              "      <td>-1.345457</td>\n",
              "      <td>-0.181773</td>\n",
              "      <td>-0.360018</td>\n",
              "      <td>-1.173974</td>\n",
              "      <td>-1.003600</td>\n",
              "      <td>0.633813</td>\n",
              "      <td>-1.036293</td>\n",
              "      <td>-0.649959</td>\n",
              "      <td>0.881835</td>\n",
              "      <td>-2.622058</td>\n",
              "      <td>1.210781</td>\n",
              "      <td>-1.647564</td>\n",
              "      <td>2.239728</td>\n",
              "      <td>-0.443698</td>\n",
              "      <td>0.008438</td>\n",
              "      <td>2.502906</td>\n",
              "      <td>0.347715</td>\n",
              "      <td>-0.337608</td>\n",
              "      <td>-1.512681</td>\n",
              "      <td>-1.112664</td>\n",
              "      <td>2.003638</td>\n",
              "      <td>-0.831244</td>\n",
              "      <td>-0.339829</td>\n",
              "      <td>1.455606</td>\n",
              "      <td>1.992911</td>\n",
              "      <td>-1.099447</td>\n",
              "      <td>2.584032</td>\n",
              "      <td>2.039423</td>\n",
              "      <td>-0.645410</td>\n",
              "      <td>0.495904</td>\n",
              "      <td>1.120493</td>\n",
              "      <td>0.265891</td>\n",
              "      <td>1.469184</td>\n",
              "      <td>0.354903</td>\n",
              "      <td>2.699039</td>\n",
              "      <td>0.795559</td>\n",
              "      <td>-1.527786</td>\n",
              "      <td>-0.215560</td>\n",
              "      <td>-2.149352</td>\n",
              "      <td>-0.513376</td>\n",
              "      <td>0.842640</td>\n",
              "      <td>3.554728</td>\n",
              "      <td>1.527833</td>\n",
              "      <td>-1.556303</td>\n",
              "      <td>-0.587206</td>\n",
              "      <td>1.662382</td>\n",
              "      <td>-0.714246</td>\n",
              "      <td>1.186730</td>\n",
              "      <td>-0.145115</td>\n",
              "      <td>0.295924</td>\n",
              "      <td>-0.532481</td>\n",
              "      <td>-1.896905</td>\n",
              "      <td>-1.239928</td>\n",
              "      <td>-3.666890</td>\n",
              "      <td>-0.901890</td>\n",
              "      <td>1.588130</td>\n",
              "      <td>0.142595</td>\n",
              "      <td>1.254227</td>\n",
              "      <td>1.221567</td>\n",
              "      <td>-2.866955</td>\n",
              "      <td>-1.190926</td>\n",
              "      <td>-1.076426</td>\n",
              "      <td>1.899313</td>\n",
              "      <td>-0.574136</td>\n",
              "      <td>1.902088</td>\n",
              "      <td>-3.170757</td>\n",
              "      <td>-1.927889</td>\n",
              "      <td>-0.800191</td>\n",
              "      <td>1.404616</td>\n",
              "      <td>0.833011</td>\n",
              "      <td>-1.435146</td>\n",
              "      <td>-0.669946</td>\n",
              "      <td>-0.628177</td>\n",
              "      <td>-2.242126</td>\n",
              "      <td>-0.026335</td>\n",
              "      <td>1.311732</td>\n",
              "      <td>0.180004</td>\n",
              "      <td>0.024092</td>\n",
              "      <td>-1.461941</td>\n",
              "      <td>-1.563753</td>\n",
              "      <td>3.114331</td>\n",
              "      <td>-0.489507</td>\n",
              "      <td>-0.035621</td>\n",
              "      <td>-0.351813</td>\n",
              "      <td>-1.816677</td>\n",
              "      <td>-0.974662</td>\n",
              "      <td>2.148677</td>\n",
              "      <td>-0.780091</td>\n",
              "      <td>0.450283</td>\n",
              "      <td>0.785037</td>\n",
              "      <td>-1.283915</td>\n",
              "      <td>0.593244</td>\n",
              "      <td>1.686675</td>\n",
              "      <td>1.344741</td>\n",
              "      <td>1.188726</td>\n",
              "      <td>3.051455</td>\n",
              "      <td>-1.061046</td>\n",
              "      <td>0.382224</td>\n",
              "      <td>0.076990</td>\n",
              "      <td>-0.719046</td>\n",
              "      <td>-1.248530</td>\n",
              "      <td>0.144460</td>\n",
              "      <td>-3.240056</td>\n",
              "      <td>0.052614</td>\n",
              "      <td>0.083108</td>\n",
              "      <td>45</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.377524</td>\n",
              "      <td>-1.018393</td>\n",
              "      <td>1.102352</td>\n",
              "      <td>2.849025</td>\n",
              "      <td>0.440302</td>\n",
              "      <td>-1.149039</td>\n",
              "      <td>-0.789796</td>\n",
              "      <td>-2.258196</td>\n",
              "      <td>1.264268</td>\n",
              "      <td>-2.123730</td>\n",
              "      <td>-1.480036</td>\n",
              "      <td>-0.370814</td>\n",
              "      <td>1.337393</td>\n",
              "      <td>1.043868</td>\n",
              "      <td>1.037037</td>\n",
              "      <td>-2.572335</td>\n",
              "      <td>0.575396</td>\n",
              "      <td>-4.482491</td>\n",
              "      <td>-1.034487</td>\n",
              "      <td>0.437354</td>\n",
              "      <td>-2.521748</td>\n",
              "      <td>1.507435</td>\n",
              "      <td>-0.274363</td>\n",
              "      <td>-3.431944</td>\n",
              "      <td>-1.560407</td>\n",
              "      <td>4.324077</td>\n",
              "      <td>-2.342700</td>\n",
              "      <td>-0.335287</td>\n",
              "      <td>-0.538335</td>\n",
              "      <td>-0.083395</td>\n",
              "      <td>-1.408175</td>\n",
              "      <td>2.230254</td>\n",
              "      <td>0.767140</td>\n",
              "      <td>0.320735</td>\n",
              "      <td>-1.722289</td>\n",
              "      <td>2.086905</td>\n",
              "      <td>-0.732669</td>\n",
              "      <td>0.833688</td>\n",
              "      <td>0.766325</td>\n",
              "      <td>1.289876</td>\n",
              "      <td>0.870834</td>\n",
              "      <td>1.620561</td>\n",
              "      <td>-0.413392</td>\n",
              "      <td>-3.004543</td>\n",
              "      <td>-1.575161</td>\n",
              "      <td>0.230717</td>\n",
              "      <td>0.709130</td>\n",
              "      <td>0.627740</td>\n",
              "      <td>1.567949</td>\n",
              "      <td>0.177835</td>\n",
              "      <td>-1.004002</td>\n",
              "      <td>0.896508</td>\n",
              "      <td>0.442845</td>\n",
              "      <td>0.568543</td>\n",
              "      <td>-1.023931</td>\n",
              "      <td>-1.813623</td>\n",
              "      <td>0.091259</td>\n",
              "      <td>-0.295286</td>\n",
              "      <td>-0.550783</td>\n",
              "      <td>-0.718510</td>\n",
              "      <td>-0.908675</td>\n",
              "      <td>-1.279681</td>\n",
              "      <td>-0.542199</td>\n",
              "      <td>2.746981</td>\n",
              "      <td>2.511886</td>\n",
              "      <td>0.305444</td>\n",
              "      <td>-1.991450</td>\n",
              "      <td>-0.180366</td>\n",
              "      <td>-0.398635</td>\n",
              "      <td>-0.093401</td>\n",
              "      <td>-0.818655</td>\n",
              "      <td>-2.229760</td>\n",
              "      <td>-0.420237</td>\n",
              "      <td>-0.177485</td>\n",
              "      <td>0.703523</td>\n",
              "      <td>1.320710</td>\n",
              "      <td>1.437858</td>\n",
              "      <td>2.810093</td>\n",
              "      <td>-2.619601</td>\n",
              "      <td>-1.280195</td>\n",
              "      <td>-1.424652</td>\n",
              "      <td>-0.265742</td>\n",
              "      <td>-0.057746</td>\n",
              "      <td>3.022341</td>\n",
              "      <td>1.991786</td>\n",
              "      <td>0.298979</td>\n",
              "      <td>-0.923647</td>\n",
              "      <td>2.248602</td>\n",
              "      <td>-0.455463</td>\n",
              "      <td>-2.657235</td>\n",
              "      <td>0.873083</td>\n",
              "      <td>0.873754</td>\n",
              "      <td>3.172528</td>\n",
              "      <td>-0.686660</td>\n",
              "      <td>1.151290</td>\n",
              "      <td>2.640462</td>\n",
              "      <td>-1.102167</td>\n",
              "      <td>0.235478</td>\n",
              "      <td>0.691108</td>\n",
              "      <td>-0.993033</td>\n",
              "      <td>0.267086</td>\n",
              "      <td>-0.978959</td>\n",
              "      <td>-0.953110</td>\n",
              "      <td>-0.689617</td>\n",
              "      <td>-3.195319</td>\n",
              "      <td>1.675777</td>\n",
              "      <td>0.991395</td>\n",
              "      <td>2.254699</td>\n",
              "      <td>1.935017</td>\n",
              "      <td>0.434932</td>\n",
              "      <td>-1.676521</td>\n",
              "      <td>0.700489</td>\n",
              "      <td>-1.825381</td>\n",
              "      <td>-0.678953</td>\n",
              "      <td>0.933151</td>\n",
              "      <td>-0.501178</td>\n",
              "      <td>0.847771</td>\n",
              "      <td>0.895918</td>\n",
              "      <td>-2.489937</td>\n",
              "      <td>0.148797</td>\n",
              "      <td>0.283701</td>\n",
              "      <td>0.977651</td>\n",
              "      <td>-0.333899</td>\n",
              "      <td>-1.185957</td>\n",
              "      <td>0.497641</td>\n",
              "      <td>-0.777000</td>\n",
              "      <td>-1.134971</td>\n",
              "      <td>-0.043783</td>\n",
              "      <td>-0.025386</td>\n",
              "      <td>-1.949964</td>\n",
              "      <td>2.903008</td>\n",
              "      <td>1.767356</td>\n",
              "      <td>-1.890247</td>\n",
              "      <td>2.130077</td>\n",
              "      <td>1.575148</td>\n",
              "      <td>-0.008119</td>\n",
              "      <td>3.133822</td>\n",
              "      <td>0.367785</td>\n",
              "      <td>1.608083</td>\n",
              "      <td>-0.738364</td>\n",
              "      <td>1.252715</td>\n",
              "      <td>-1.298761</td>\n",
              "      <td>0.438147</td>\n",
              "      <td>0.505633</td>\n",
              "      <td>0.907046</td>\n",
              "      <td>0.426572</td>\n",
              "      <td>1.318294</td>\n",
              "      <td>0.773356</td>\n",
              "      <td>-0.013219</td>\n",
              "      <td>-0.044907</td>\n",
              "      <td>-1.144436</td>\n",
              "      <td>0.913065</td>\n",
              "      <td>-0.714127</td>\n",
              "      <td>-1.729165</td>\n",
              "      <td>-0.020797</td>\n",
              "      <td>-0.557447</td>\n",
              "      <td>1.587982</td>\n",
              "      <td>-2.157808</td>\n",
              "      <td>-1.205578</td>\n",
              "      <td>2.327618</td>\n",
              "      <td>-1.701403</td>\n",
              "      <td>1.248531</td>\n",
              "      <td>-2.182585</td>\n",
              "      <td>1.814523</td>\n",
              "      <td>0.075408</td>\n",
              "      <td>-1.357059</td>\n",
              "      <td>1.987957</td>\n",
              "      <td>-0.213262</td>\n",
              "      <td>-1.066381</td>\n",
              "      <td>-1.749353</td>\n",
              "      <td>-1.179543</td>\n",
              "      <td>2.229092</td>\n",
              "      <td>-1.711803</td>\n",
              "      <td>0.469646</td>\n",
              "      <td>1.162583</td>\n",
              "      <td>2.181157</td>\n",
              "      <td>-1.407149</td>\n",
              "      <td>2.457415</td>\n",
              "      <td>0.694950</td>\n",
              "      <td>-0.728181</td>\n",
              "      <td>1.278901</td>\n",
              "      <td>1.337580</td>\n",
              "      <td>0.184999</td>\n",
              "      <td>1.624231</td>\n",
              "      <td>-1.367010</td>\n",
              "      <td>2.136319</td>\n",
              "      <td>1.370169</td>\n",
              "      <td>-1.095014</td>\n",
              "      <td>-2.382134</td>\n",
              "      <td>-1.737152</td>\n",
              "      <td>0.044933</td>\n",
              "      <td>0.746034</td>\n",
              "      <td>1.877104</td>\n",
              "      <td>1.332648</td>\n",
              "      <td>-0.199040</td>\n",
              "      <td>0.101963</td>\n",
              "      <td>1.495080</td>\n",
              "      <td>-1.017038</td>\n",
              "      <td>0.186521</td>\n",
              "      <td>-1.309609</td>\n",
              "      <td>0.472736</td>\n",
              "      <td>-0.861389</td>\n",
              "      <td>-1.989814</td>\n",
              "      <td>-0.465665</td>\n",
              "      <td>-3.516261</td>\n",
              "      <td>-0.593888</td>\n",
              "      <td>1.215666</td>\n",
              "      <td>-0.459955</td>\n",
              "      <td>0.721586</td>\n",
              "      <td>1.316415</td>\n",
              "      <td>-3.599638</td>\n",
              "      <td>-1.353255</td>\n",
              "      <td>-2.604110</td>\n",
              "      <td>2.856650</td>\n",
              "      <td>-0.800402</td>\n",
              "      <td>1.819534</td>\n",
              "      <td>-3.557524</td>\n",
              "      <td>-0.337203</td>\n",
              "      <td>-0.608348</td>\n",
              "      <td>1.265913</td>\n",
              "      <td>0.661117</td>\n",
              "      <td>-2.093112</td>\n",
              "      <td>-0.760502</td>\n",
              "      <td>0.471058</td>\n",
              "      <td>-0.604653</td>\n",
              "      <td>-0.017820</td>\n",
              "      <td>1.238391</td>\n",
              "      <td>1.020576</td>\n",
              "      <td>-0.097181</td>\n",
              "      <td>-2.133749</td>\n",
              "      <td>-0.895949</td>\n",
              "      <td>1.529343</td>\n",
              "      <td>0.231963</td>\n",
              "      <td>1.697689</td>\n",
              "      <td>-0.519540</td>\n",
              "      <td>-2.491656</td>\n",
              "      <td>-0.655185</td>\n",
              "      <td>1.620014</td>\n",
              "      <td>-0.845751</td>\n",
              "      <td>0.494454</td>\n",
              "      <td>-0.271467</td>\n",
              "      <td>-1.795943</td>\n",
              "      <td>0.440410</td>\n",
              "      <td>3.982734</td>\n",
              "      <td>0.319849</td>\n",
              "      <td>1.118826</td>\n",
              "      <td>1.343224</td>\n",
              "      <td>0.120304</td>\n",
              "      <td>-0.066218</td>\n",
              "      <td>-0.231481</td>\n",
              "      <td>-1.383339</td>\n",
              "      <td>-0.787736</td>\n",
              "      <td>1.044895</td>\n",
              "      <td>-2.289637</td>\n",
              "      <td>0.199752</td>\n",
              "      <td>-0.712154</td>\n",
              "      <td>45</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.889574</td>\n",
              "      <td>-2.743300</td>\n",
              "      <td>-0.320194</td>\n",
              "      <td>3.047766</td>\n",
              "      <td>-0.923335</td>\n",
              "      <td>1.741686</td>\n",
              "      <td>-0.615148</td>\n",
              "      <td>0.756482</td>\n",
              "      <td>2.074775</td>\n",
              "      <td>-1.433126</td>\n",
              "      <td>-0.068064</td>\n",
              "      <td>0.598540</td>\n",
              "      <td>1.747028</td>\n",
              "      <td>0.308814</td>\n",
              "      <td>1.438595</td>\n",
              "      <td>-2.713891</td>\n",
              "      <td>-1.504777</td>\n",
              "      <td>-4.458522</td>\n",
              "      <td>0.155936</td>\n",
              "      <td>0.417320</td>\n",
              "      <td>-4.085610</td>\n",
              "      <td>1.279542</td>\n",
              "      <td>0.348400</td>\n",
              "      <td>-0.366978</td>\n",
              "      <td>-2.583359</td>\n",
              "      <td>2.598797</td>\n",
              "      <td>0.575795</td>\n",
              "      <td>0.082680</td>\n",
              "      <td>-0.442469</td>\n",
              "      <td>-0.837585</td>\n",
              "      <td>-0.474353</td>\n",
              "      <td>0.484577</td>\n",
              "      <td>-2.375412</td>\n",
              "      <td>1.408367</td>\n",
              "      <td>-0.847942</td>\n",
              "      <td>0.744728</td>\n",
              "      <td>0.338863</td>\n",
              "      <td>-0.330735</td>\n",
              "      <td>-0.162522</td>\n",
              "      <td>0.452853</td>\n",
              "      <td>0.040784</td>\n",
              "      <td>0.636638</td>\n",
              "      <td>0.488008</td>\n",
              "      <td>-2.807750</td>\n",
              "      <td>-0.646960</td>\n",
              "      <td>0.408045</td>\n",
              "      <td>-1.926035</td>\n",
              "      <td>-0.817600</td>\n",
              "      <td>1.965834</td>\n",
              "      <td>1.634271</td>\n",
              "      <td>-0.057730</td>\n",
              "      <td>-1.051165</td>\n",
              "      <td>-0.985080</td>\n",
              "      <td>-1.028156</td>\n",
              "      <td>-2.506213</td>\n",
              "      <td>-0.687154</td>\n",
              "      <td>0.882658</td>\n",
              "      <td>3.042392</td>\n",
              "      <td>0.408750</td>\n",
              "      <td>-0.388141</td>\n",
              "      <td>1.037253</td>\n",
              "      <td>-0.013801</td>\n",
              "      <td>-1.073934</td>\n",
              "      <td>2.696985</td>\n",
              "      <td>1.102886</td>\n",
              "      <td>1.107540</td>\n",
              "      <td>-1.580062</td>\n",
              "      <td>0.529930</td>\n",
              "      <td>-1.735664</td>\n",
              "      <td>2.087687</td>\n",
              "      <td>-1.865816</td>\n",
              "      <td>-1.085436</td>\n",
              "      <td>2.077800</td>\n",
              "      <td>2.181563</td>\n",
              "      <td>0.676282</td>\n",
              "      <td>1.537059</td>\n",
              "      <td>0.437179</td>\n",
              "      <td>3.207828</td>\n",
              "      <td>-0.948437</td>\n",
              "      <td>0.361401</td>\n",
              "      <td>-0.624320</td>\n",
              "      <td>-2.360142</td>\n",
              "      <td>-3.044507</td>\n",
              "      <td>0.900405</td>\n",
              "      <td>0.894809</td>\n",
              "      <td>1.611774</td>\n",
              "      <td>-0.082311</td>\n",
              "      <td>3.067043</td>\n",
              "      <td>0.781910</td>\n",
              "      <td>-3.374880</td>\n",
              "      <td>1.657745</td>\n",
              "      <td>2.621795</td>\n",
              "      <td>0.566249</td>\n",
              "      <td>1.616813</td>\n",
              "      <td>0.483428</td>\n",
              "      <td>2.613995</td>\n",
              "      <td>0.053810</td>\n",
              "      <td>-0.163222</td>\n",
              "      <td>1.368764</td>\n",
              "      <td>2.882331</td>\n",
              "      <td>1.319969</td>\n",
              "      <td>-0.076523</td>\n",
              "      <td>0.292585</td>\n",
              "      <td>0.424204</td>\n",
              "      <td>-3.125484</td>\n",
              "      <td>4.271754</td>\n",
              "      <td>0.003506</td>\n",
              "      <td>2.165426</td>\n",
              "      <td>2.216364</td>\n",
              "      <td>1.274847</td>\n",
              "      <td>-2.215402</td>\n",
              "      <td>2.470454</td>\n",
              "      <td>-2.996966</td>\n",
              "      <td>-1.834035</td>\n",
              "      <td>-0.470077</td>\n",
              "      <td>-0.512093</td>\n",
              "      <td>-1.698522</td>\n",
              "      <td>1.150141</td>\n",
              "      <td>-1.353543</td>\n",
              "      <td>2.651054</td>\n",
              "      <td>1.000973</td>\n",
              "      <td>3.791727</td>\n",
              "      <td>0.927324</td>\n",
              "      <td>2.259706</td>\n",
              "      <td>0.299818</td>\n",
              "      <td>-0.181001</td>\n",
              "      <td>-2.243796</td>\n",
              "      <td>2.582069</td>\n",
              "      <td>2.752008</td>\n",
              "      <td>-3.786018</td>\n",
              "      <td>1.871401</td>\n",
              "      <td>1.600301</td>\n",
              "      <td>-3.499447</td>\n",
              "      <td>0.890145</td>\n",
              "      <td>3.201261</td>\n",
              "      <td>-0.732026</td>\n",
              "      <td>2.355211</td>\n",
              "      <td>-1.167341</td>\n",
              "      <td>0.308718</td>\n",
              "      <td>1.244494</td>\n",
              "      <td>2.741512</td>\n",
              "      <td>-1.443089</td>\n",
              "      <td>1.920954</td>\n",
              "      <td>1.407865</td>\n",
              "      <td>-0.812475</td>\n",
              "      <td>0.641355</td>\n",
              "      <td>-1.667917</td>\n",
              "      <td>0.403139</td>\n",
              "      <td>-0.627385</td>\n",
              "      <td>-2.674358</td>\n",
              "      <td>0.084885</td>\n",
              "      <td>-0.538724</td>\n",
              "      <td>-0.972709</td>\n",
              "      <td>-1.782716</td>\n",
              "      <td>1.740537</td>\n",
              "      <td>-0.204722</td>\n",
              "      <td>-1.108238</td>\n",
              "      <td>-2.753174</td>\n",
              "      <td>0.128128</td>\n",
              "      <td>2.109432</td>\n",
              "      <td>-0.431198</td>\n",
              "      <td>-0.746089</td>\n",
              "      <td>-1.905429</td>\n",
              "      <td>2.762295</td>\n",
              "      <td>-2.902401</td>\n",
              "      <td>0.157960</td>\n",
              "      <td>0.131560</td>\n",
              "      <td>0.846749</td>\n",
              "      <td>-0.749586</td>\n",
              "      <td>-3.943792</td>\n",
              "      <td>-0.819606</td>\n",
              "      <td>1.675375</td>\n",
              "      <td>-2.978254</td>\n",
              "      <td>1.972330</td>\n",
              "      <td>-0.681611</td>\n",
              "      <td>1.101892</td>\n",
              "      <td>2.447925</td>\n",
              "      <td>1.333436</td>\n",
              "      <td>0.530785</td>\n",
              "      <td>-1.137186</td>\n",
              "      <td>0.758588</td>\n",
              "      <td>0.565381</td>\n",
              "      <td>-0.253345</td>\n",
              "      <td>1.268174</td>\n",
              "      <td>-2.279669</td>\n",
              "      <td>0.942738</td>\n",
              "      <td>2.148296</td>\n",
              "      <td>0.781780</td>\n",
              "      <td>-1.431568</td>\n",
              "      <td>-2.320069</td>\n",
              "      <td>-0.521101</td>\n",
              "      <td>1.436933</td>\n",
              "      <td>0.612523</td>\n",
              "      <td>0.770629</td>\n",
              "      <td>-0.497572</td>\n",
              "      <td>0.425608</td>\n",
              "      <td>-1.119316</td>\n",
              "      <td>-0.393558</td>\n",
              "      <td>1.740232</td>\n",
              "      <td>-2.451356</td>\n",
              "      <td>2.294403</td>\n",
              "      <td>2.709764</td>\n",
              "      <td>-2.017183</td>\n",
              "      <td>-0.235833</td>\n",
              "      <td>-2.430242</td>\n",
              "      <td>1.457975</td>\n",
              "      <td>-0.622639</td>\n",
              "      <td>1.224396</td>\n",
              "      <td>1.235596</td>\n",
              "      <td>1.519492</td>\n",
              "      <td>-0.524034</td>\n",
              "      <td>-1.654578</td>\n",
              "      <td>-2.101801</td>\n",
              "      <td>-0.941467</td>\n",
              "      <td>-1.796806</td>\n",
              "      <td>2.479564</td>\n",
              "      <td>-0.038002</td>\n",
              "      <td>-3.641708</td>\n",
              "      <td>-0.018166</td>\n",
              "      <td>3.271545</td>\n",
              "      <td>0.378753</td>\n",
              "      <td>-0.108741</td>\n",
              "      <td>-2.073370</td>\n",
              "      <td>-2.594663</td>\n",
              "      <td>-0.569902</td>\n",
              "      <td>-2.202442</td>\n",
              "      <td>1.376741</td>\n",
              "      <td>-0.607759</td>\n",
              "      <td>2.355708</td>\n",
              "      <td>-3.633044</td>\n",
              "      <td>0.252401</td>\n",
              "      <td>1.554519</td>\n",
              "      <td>0.908245</td>\n",
              "      <td>0.548797</td>\n",
              "      <td>-2.824641</td>\n",
              "      <td>-1.486418</td>\n",
              "      <td>1.806167</td>\n",
              "      <td>1.680712</td>\n",
              "      <td>0.691597</td>\n",
              "      <td>1.551380</td>\n",
              "      <td>0.683709</td>\n",
              "      <td>0.983895</td>\n",
              "      <td>0.019876</td>\n",
              "      <td>0.513138</td>\n",
              "      <td>-0.852068</td>\n",
              "      <td>0.368997</td>\n",
              "      <td>3.139382</td>\n",
              "      <td>-1.166126</td>\n",
              "      <td>-1.299070</td>\n",
              "      <td>-2.486144</td>\n",
              "      <td>1.178322</td>\n",
              "      <td>0.035333</td>\n",
              "      <td>0.857712</td>\n",
              "      <td>-1.928684</td>\n",
              "      <td>0.639870</td>\n",
              "      <td>-0.268576</td>\n",
              "      <td>45</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.527213</td>\n",
              "      <td>-1.133121</td>\n",
              "      <td>0.385927</td>\n",
              "      <td>3.129767</td>\n",
              "      <td>0.229020</td>\n",
              "      <td>1.373105</td>\n",
              "      <td>0.919284</td>\n",
              "      <td>-0.755558</td>\n",
              "      <td>1.086973</td>\n",
              "      <td>-2.440614</td>\n",
              "      <td>-0.565188</td>\n",
              "      <td>-1.627237</td>\n",
              "      <td>1.396390</td>\n",
              "      <td>1.128513</td>\n",
              "      <td>-0.493460</td>\n",
              "      <td>-0.038711</td>\n",
              "      <td>0.602175</td>\n",
              "      <td>-3.371845</td>\n",
              "      <td>-2.498516</td>\n",
              "      <td>2.503236</td>\n",
              "      <td>-2.435895</td>\n",
              "      <td>0.942354</td>\n",
              "      <td>0.043507</td>\n",
              "      <td>-2.201002</td>\n",
              "      <td>-0.735961</td>\n",
              "      <td>3.204553</td>\n",
              "      <td>-1.264879</td>\n",
              "      <td>0.635861</td>\n",
              "      <td>-3.064966</td>\n",
              "      <td>-2.655011</td>\n",
              "      <td>-0.296643</td>\n",
              "      <td>2.477197</td>\n",
              "      <td>-1.534483</td>\n",
              "      <td>-1.056755</td>\n",
              "      <td>-0.100055</td>\n",
              "      <td>1.764300</td>\n",
              "      <td>0.323443</td>\n",
              "      <td>-0.412691</td>\n",
              "      <td>0.305619</td>\n",
              "      <td>-0.170311</td>\n",
              "      <td>0.290808</td>\n",
              "      <td>0.765568</td>\n",
              "      <td>0.568708</td>\n",
              "      <td>-2.309546</td>\n",
              "      <td>-0.082422</td>\n",
              "      <td>-0.406527</td>\n",
              "      <td>-0.130403</td>\n",
              "      <td>-1.042421</td>\n",
              "      <td>1.668278</td>\n",
              "      <td>0.076061</td>\n",
              "      <td>-0.624170</td>\n",
              "      <td>-0.340301</td>\n",
              "      <td>-0.232693</td>\n",
              "      <td>-0.694077</td>\n",
              "      <td>0.120609</td>\n",
              "      <td>-0.181700</td>\n",
              "      <td>-1.227839</td>\n",
              "      <td>1.517968</td>\n",
              "      <td>-0.254498</td>\n",
              "      <td>-1.156026</td>\n",
              "      <td>0.845028</td>\n",
              "      <td>-1.565275</td>\n",
              "      <td>-2.187371</td>\n",
              "      <td>2.092654</td>\n",
              "      <td>-0.277010</td>\n",
              "      <td>0.747036</td>\n",
              "      <td>-2.091516</td>\n",
              "      <td>0.248123</td>\n",
              "      <td>-1.513840</td>\n",
              "      <td>1.145658</td>\n",
              "      <td>0.720055</td>\n",
              "      <td>-1.349451</td>\n",
              "      <td>0.580730</td>\n",
              "      <td>-0.639348</td>\n",
              "      <td>0.919229</td>\n",
              "      <td>-0.793818</td>\n",
              "      <td>-0.373706</td>\n",
              "      <td>4.089901</td>\n",
              "      <td>-0.264145</td>\n",
              "      <td>-1.705614</td>\n",
              "      <td>-0.755140</td>\n",
              "      <td>0.809717</td>\n",
              "      <td>-1.598379</td>\n",
              "      <td>3.160564</td>\n",
              "      <td>1.170041</td>\n",
              "      <td>1.224120</td>\n",
              "      <td>-0.914786</td>\n",
              "      <td>2.774773</td>\n",
              "      <td>0.408935</td>\n",
              "      <td>-1.848639</td>\n",
              "      <td>3.260644</td>\n",
              "      <td>-0.466688</td>\n",
              "      <td>1.058204</td>\n",
              "      <td>1.590415</td>\n",
              "      <td>-0.732783</td>\n",
              "      <td>3.119562</td>\n",
              "      <td>0.739683</td>\n",
              "      <td>1.613508</td>\n",
              "      <td>0.940187</td>\n",
              "      <td>2.606899</td>\n",
              "      <td>-0.622144</td>\n",
              "      <td>0.346026</td>\n",
              "      <td>-1.391296</td>\n",
              "      <td>1.045245</td>\n",
              "      <td>-2.003494</td>\n",
              "      <td>4.174849</td>\n",
              "      <td>-0.889034</td>\n",
              "      <td>2.308643</td>\n",
              "      <td>1.999224</td>\n",
              "      <td>2.193147</td>\n",
              "      <td>-3.366686</td>\n",
              "      <td>0.717010</td>\n",
              "      <td>-1.075971</td>\n",
              "      <td>0.606645</td>\n",
              "      <td>1.389568</td>\n",
              "      <td>-0.699702</td>\n",
              "      <td>0.320103</td>\n",
              "      <td>0.402176</td>\n",
              "      <td>-0.800103</td>\n",
              "      <td>1.534205</td>\n",
              "      <td>0.774308</td>\n",
              "      <td>0.487083</td>\n",
              "      <td>0.152025</td>\n",
              "      <td>1.375199</td>\n",
              "      <td>-1.602308</td>\n",
              "      <td>-0.341696</td>\n",
              "      <td>-1.842209</td>\n",
              "      <td>1.203861</td>\n",
              "      <td>0.353427</td>\n",
              "      <td>-2.607541</td>\n",
              "      <td>4.440294</td>\n",
              "      <td>2.010852</td>\n",
              "      <td>-0.234556</td>\n",
              "      <td>1.379486</td>\n",
              "      <td>3.946222</td>\n",
              "      <td>-0.057069</td>\n",
              "      <td>2.892920</td>\n",
              "      <td>0.206937</td>\n",
              "      <td>-0.017862</td>\n",
              "      <td>-1.035440</td>\n",
              "      <td>1.826345</td>\n",
              "      <td>-1.320592</td>\n",
              "      <td>1.831217</td>\n",
              "      <td>0.570368</td>\n",
              "      <td>0.975892</td>\n",
              "      <td>-1.335703</td>\n",
              "      <td>-0.108493</td>\n",
              "      <td>0.178833</td>\n",
              "      <td>-0.060930</td>\n",
              "      <td>0.022329</td>\n",
              "      <td>0.501405</td>\n",
              "      <td>-0.963698</td>\n",
              "      <td>-0.611106</td>\n",
              "      <td>0.011987</td>\n",
              "      <td>1.349425</td>\n",
              "      <td>-0.327173</td>\n",
              "      <td>0.196352</td>\n",
              "      <td>-2.444371</td>\n",
              "      <td>-0.828266</td>\n",
              "      <td>1.982651</td>\n",
              "      <td>-0.822506</td>\n",
              "      <td>1.120825</td>\n",
              "      <td>-0.263532</td>\n",
              "      <td>1.384485</td>\n",
              "      <td>-1.324554</td>\n",
              "      <td>-1.652047</td>\n",
              "      <td>2.036757</td>\n",
              "      <td>0.884038</td>\n",
              "      <td>-0.073252</td>\n",
              "      <td>-3.039382</td>\n",
              "      <td>-1.048928</td>\n",
              "      <td>1.850740</td>\n",
              "      <td>-1.708344</td>\n",
              "      <td>0.239440</td>\n",
              "      <td>-0.432976</td>\n",
              "      <td>1.396593</td>\n",
              "      <td>2.401515</td>\n",
              "      <td>1.437454</td>\n",
              "      <td>-0.097905</td>\n",
              "      <td>-0.054642</td>\n",
              "      <td>0.111235</td>\n",
              "      <td>2.007907</td>\n",
              "      <td>-0.104267</td>\n",
              "      <td>0.837830</td>\n",
              "      <td>-2.229129</td>\n",
              "      <td>1.292541</td>\n",
              "      <td>1.866845</td>\n",
              "      <td>1.043962</td>\n",
              "      <td>-1.218874</td>\n",
              "      <td>-1.378514</td>\n",
              "      <td>-0.957665</td>\n",
              "      <td>2.771368</td>\n",
              "      <td>2.257250</td>\n",
              "      <td>1.245677</td>\n",
              "      <td>-2.075094</td>\n",
              "      <td>2.186147</td>\n",
              "      <td>-0.314110</td>\n",
              "      <td>-1.259806</td>\n",
              "      <td>0.409803</td>\n",
              "      <td>-1.699620</td>\n",
              "      <td>0.186563</td>\n",
              "      <td>-0.758017</td>\n",
              "      <td>0.871980</td>\n",
              "      <td>-0.486622</td>\n",
              "      <td>-2.341567</td>\n",
              "      <td>0.897780</td>\n",
              "      <td>-0.065674</td>\n",
              "      <td>1.860209</td>\n",
              "      <td>1.643175</td>\n",
              "      <td>0.045659</td>\n",
              "      <td>-2.051654</td>\n",
              "      <td>-0.683399</td>\n",
              "      <td>-0.542855</td>\n",
              "      <td>0.725036</td>\n",
              "      <td>-2.858389</td>\n",
              "      <td>2.773426</td>\n",
              "      <td>-1.226120</td>\n",
              "      <td>-2.527034</td>\n",
              "      <td>0.747429</td>\n",
              "      <td>1.975456</td>\n",
              "      <td>0.500852</td>\n",
              "      <td>-0.860470</td>\n",
              "      <td>-0.675475</td>\n",
              "      <td>0.340702</td>\n",
              "      <td>0.500773</td>\n",
              "      <td>-0.627366</td>\n",
              "      <td>-0.645546</td>\n",
              "      <td>-0.463846</td>\n",
              "      <td>2.623931</td>\n",
              "      <td>-1.914251</td>\n",
              "      <td>0.088570</td>\n",
              "      <td>1.994985</td>\n",
              "      <td>1.659639</td>\n",
              "      <td>1.896314</td>\n",
              "      <td>-0.711247</td>\n",
              "      <td>-2.300663</td>\n",
              "      <td>1.871941</td>\n",
              "      <td>0.919648</td>\n",
              "      <td>-0.882903</td>\n",
              "      <td>0.966500</td>\n",
              "      <td>0.635516</td>\n",
              "      <td>-0.666670</td>\n",
              "      <td>-0.847318</td>\n",
              "      <td>0.675496</td>\n",
              "      <td>1.160198</td>\n",
              "      <td>-1.155169</td>\n",
              "      <td>0.029133</td>\n",
              "      <td>-1.663985</td>\n",
              "      <td>-0.865878</td>\n",
              "      <td>-1.387906</td>\n",
              "      <td>-0.664176</td>\n",
              "      <td>0.805059</td>\n",
              "      <td>0.975368</td>\n",
              "      <td>-2.700269</td>\n",
              "      <td>1.523236</td>\n",
              "      <td>-1.259052</td>\n",
              "      <td>45</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.948176</td>\n",
              "      <td>-0.750248</td>\n",
              "      <td>0.008329</td>\n",
              "      <td>1.675338</td>\n",
              "      <td>1.941155</td>\n",
              "      <td>-0.783623</td>\n",
              "      <td>-0.485584</td>\n",
              "      <td>-0.261882</td>\n",
              "      <td>2.875204</td>\n",
              "      <td>-1.473030</td>\n",
              "      <td>-0.160699</td>\n",
              "      <td>0.289259</td>\n",
              "      <td>2.305159</td>\n",
              "      <td>-0.126328</td>\n",
              "      <td>-0.222299</td>\n",
              "      <td>-2.617932</td>\n",
              "      <td>-0.619935</td>\n",
              "      <td>-4.951178</td>\n",
              "      <td>-0.346735</td>\n",
              "      <td>1.704095</td>\n",
              "      <td>-3.009544</td>\n",
              "      <td>0.741036</td>\n",
              "      <td>0.611817</td>\n",
              "      <td>-2.723161</td>\n",
              "      <td>-1.415860</td>\n",
              "      <td>1.361665</td>\n",
              "      <td>-1.888240</td>\n",
              "      <td>1.091696</td>\n",
              "      <td>-0.375257</td>\n",
              "      <td>-1.554744</td>\n",
              "      <td>-0.669312</td>\n",
              "      <td>2.200294</td>\n",
              "      <td>-0.712490</td>\n",
              "      <td>2.395652</td>\n",
              "      <td>0.465258</td>\n",
              "      <td>3.061924</td>\n",
              "      <td>-1.661386</td>\n",
              "      <td>0.511598</td>\n",
              "      <td>1.307248</td>\n",
              "      <td>0.204698</td>\n",
              "      <td>1.896613</td>\n",
              "      <td>0.959890</td>\n",
              "      <td>0.726368</td>\n",
              "      <td>-4.255481</td>\n",
              "      <td>-2.185033</td>\n",
              "      <td>0.425133</td>\n",
              "      <td>1.109373</td>\n",
              "      <td>-0.356726</td>\n",
              "      <td>0.777323</td>\n",
              "      <td>1.211375</td>\n",
              "      <td>0.702060</td>\n",
              "      <td>0.255479</td>\n",
              "      <td>0.439791</td>\n",
              "      <td>-1.058073</td>\n",
              "      <td>-1.484549</td>\n",
              "      <td>0.925864</td>\n",
              "      <td>0.694274</td>\n",
              "      <td>2.415081</td>\n",
              "      <td>0.112275</td>\n",
              "      <td>-1.632634</td>\n",
              "      <td>0.566655</td>\n",
              "      <td>-0.339927</td>\n",
              "      <td>-1.295883</td>\n",
              "      <td>2.088299</td>\n",
              "      <td>2.267484</td>\n",
              "      <td>-0.299912</td>\n",
              "      <td>-0.205782</td>\n",
              "      <td>1.263023</td>\n",
              "      <td>-1.989637</td>\n",
              "      <td>1.348971</td>\n",
              "      <td>-1.039191</td>\n",
              "      <td>-1.875184</td>\n",
              "      <td>0.721441</td>\n",
              "      <td>0.294191</td>\n",
              "      <td>0.221436</td>\n",
              "      <td>0.792514</td>\n",
              "      <td>-0.752636</td>\n",
              "      <td>5.088836</td>\n",
              "      <td>0.496678</td>\n",
              "      <td>-0.984859</td>\n",
              "      <td>-0.562585</td>\n",
              "      <td>-2.258661</td>\n",
              "      <td>-1.817895</td>\n",
              "      <td>2.861654</td>\n",
              "      <td>0.981906</td>\n",
              "      <td>-0.947889</td>\n",
              "      <td>0.441403</td>\n",
              "      <td>1.367464</td>\n",
              "      <td>0.099122</td>\n",
              "      <td>-4.565517</td>\n",
              "      <td>1.476906</td>\n",
              "      <td>0.694022</td>\n",
              "      <td>0.628808</td>\n",
              "      <td>1.002152</td>\n",
              "      <td>0.463058</td>\n",
              "      <td>2.210602</td>\n",
              "      <td>-0.190344</td>\n",
              "      <td>-0.726012</td>\n",
              "      <td>-0.484766</td>\n",
              "      <td>-0.137692</td>\n",
              "      <td>0.954836</td>\n",
              "      <td>1.820612</td>\n",
              "      <td>-1.137770</td>\n",
              "      <td>0.878297</td>\n",
              "      <td>-2.351335</td>\n",
              "      <td>2.699015</td>\n",
              "      <td>-0.645027</td>\n",
              "      <td>3.779342</td>\n",
              "      <td>0.871177</td>\n",
              "      <td>1.013069</td>\n",
              "      <td>-2.018157</td>\n",
              "      <td>0.833605</td>\n",
              "      <td>-3.071455</td>\n",
              "      <td>-1.480018</td>\n",
              "      <td>0.664669</td>\n",
              "      <td>-0.201570</td>\n",
              "      <td>-0.583158</td>\n",
              "      <td>-1.364045</td>\n",
              "      <td>-2.453391</td>\n",
              "      <td>0.240503</td>\n",
              "      <td>0.186601</td>\n",
              "      <td>1.818926</td>\n",
              "      <td>-0.742571</td>\n",
              "      <td>-0.037177</td>\n",
              "      <td>1.280065</td>\n",
              "      <td>0.518486</td>\n",
              "      <td>-1.779763</td>\n",
              "      <td>0.429643</td>\n",
              "      <td>0.878478</td>\n",
              "      <td>-1.078574</td>\n",
              "      <td>3.409653</td>\n",
              "      <td>1.151645</td>\n",
              "      <td>-2.423276</td>\n",
              "      <td>2.432567</td>\n",
              "      <td>1.464046</td>\n",
              "      <td>0.792889</td>\n",
              "      <td>1.594565</td>\n",
              "      <td>0.362187</td>\n",
              "      <td>0.413490</td>\n",
              "      <td>0.325162</td>\n",
              "      <td>1.090187</td>\n",
              "      <td>-3.228460</td>\n",
              "      <td>0.707163</td>\n",
              "      <td>1.954086</td>\n",
              "      <td>0.877493</td>\n",
              "      <td>1.466568</td>\n",
              "      <td>-0.396870</td>\n",
              "      <td>1.685474</td>\n",
              "      <td>-0.330427</td>\n",
              "      <td>-0.978125</td>\n",
              "      <td>-0.687624</td>\n",
              "      <td>-0.895253</td>\n",
              "      <td>-0.444210</td>\n",
              "      <td>-0.605341</td>\n",
              "      <td>-1.032263</td>\n",
              "      <td>-0.666210</td>\n",
              "      <td>-0.301659</td>\n",
              "      <td>-2.534818</td>\n",
              "      <td>0.324984</td>\n",
              "      <td>0.993940</td>\n",
              "      <td>0.535053</td>\n",
              "      <td>-0.874236</td>\n",
              "      <td>-1.659583</td>\n",
              "      <td>2.242578</td>\n",
              "      <td>-0.775007</td>\n",
              "      <td>-0.137154</td>\n",
              "      <td>1.877279</td>\n",
              "      <td>-0.892328</td>\n",
              "      <td>-0.911374</td>\n",
              "      <td>-2.287852</td>\n",
              "      <td>-1.846204</td>\n",
              "      <td>0.974298</td>\n",
              "      <td>-1.766163</td>\n",
              "      <td>-0.013610</td>\n",
              "      <td>0.904179</td>\n",
              "      <td>0.108735</td>\n",
              "      <td>-0.103769</td>\n",
              "      <td>1.152863</td>\n",
              "      <td>-0.736740</td>\n",
              "      <td>-3.496263</td>\n",
              "      <td>0.802070</td>\n",
              "      <td>-0.375151</td>\n",
              "      <td>-3.010861</td>\n",
              "      <td>1.026657</td>\n",
              "      <td>-0.218227</td>\n",
              "      <td>2.181341</td>\n",
              "      <td>0.940091</td>\n",
              "      <td>0.462749</td>\n",
              "      <td>-0.498019</td>\n",
              "      <td>-3.216477</td>\n",
              "      <td>-0.724057</td>\n",
              "      <td>1.795768</td>\n",
              "      <td>1.609647</td>\n",
              "      <td>0.879645</td>\n",
              "      <td>-0.619501</td>\n",
              "      <td>0.251506</td>\n",
              "      <td>-1.245882</td>\n",
              "      <td>-0.059462</td>\n",
              "      <td>0.382695</td>\n",
              "      <td>-1.949562</td>\n",
              "      <td>1.221119</td>\n",
              "      <td>2.630744</td>\n",
              "      <td>-0.233323</td>\n",
              "      <td>-0.066793</td>\n",
              "      <td>-2.093198</td>\n",
              "      <td>0.781117</td>\n",
              "      <td>-0.230964</td>\n",
              "      <td>0.694065</td>\n",
              "      <td>1.086709</td>\n",
              "      <td>0.793822</td>\n",
              "      <td>-1.910584</td>\n",
              "      <td>-1.488135</td>\n",
              "      <td>0.329182</td>\n",
              "      <td>3.073059</td>\n",
              "      <td>-0.513672</td>\n",
              "      <td>-0.266794</td>\n",
              "      <td>-0.925509</td>\n",
              "      <td>-3.195087</td>\n",
              "      <td>-0.426922</td>\n",
              "      <td>1.637993</td>\n",
              "      <td>1.364704</td>\n",
              "      <td>0.528615</td>\n",
              "      <td>-0.684009</td>\n",
              "      <td>-0.323255</td>\n",
              "      <td>-1.894410</td>\n",
              "      <td>-0.988054</td>\n",
              "      <td>1.570205</td>\n",
              "      <td>-1.842084</td>\n",
              "      <td>1.099123</td>\n",
              "      <td>-1.361982</td>\n",
              "      <td>0.285133</td>\n",
              "      <td>2.951020</td>\n",
              "      <td>1.548886</td>\n",
              "      <td>0.000797</td>\n",
              "      <td>-0.820848</td>\n",
              "      <td>-0.469899</td>\n",
              "      <td>0.312798</td>\n",
              "      <td>-0.188478</td>\n",
              "      <td>0.567227</td>\n",
              "      <td>0.456920</td>\n",
              "      <td>0.230514</td>\n",
              "      <td>-1.348908</td>\n",
              "      <td>-1.371241</td>\n",
              "      <td>1.603917</td>\n",
              "      <td>0.299558</td>\n",
              "      <td>-1.909181</td>\n",
              "      <td>-0.295354</td>\n",
              "      <td>0.061812</td>\n",
              "      <td>-0.368456</td>\n",
              "      <td>0.344975</td>\n",
              "      <td>-0.665200</td>\n",
              "      <td>-0.428060</td>\n",
              "      <td>-0.393100</td>\n",
              "      <td>-1.854657</td>\n",
              "      <td>2.207063</td>\n",
              "      <td>-0.342725</td>\n",
              "      <td>45</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-36993fec-5f79-43c0-bfe5-2b1e5eace78b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-36993fec-5f79-43c0-bfe5-2b1e5eace78b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-36993fec-5f79-43c0-bfe5-2b1e5eace78b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-88a47d59-d551-4935-bd0b-effa8999ede9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-88a47d59-d551-4935-bd0b-effa8999ede9')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-88a47d59-d551-4935-bd0b-effa8999ede9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "## print the top5 records\n",
        "train_dataset.head()\n",
        "valid_dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GL6IYMW_RCi"
      },
      "source": [
        "# Check for Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5oAN0H1_S3C",
        "outputId": "f52c7142-ace1-4bc5-b099-d14c2fb6fb2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No missing values found in the selected features.\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Make a list of features with missing values, excluding the last 4 columns\n",
        "features_with_na = [feature for feature in train_dataset.columns[:-4] if train_dataset[feature].isnull().sum() > 1]\n",
        "\n",
        "# Step 2: Check if there are any features with missing values\n",
        "if not features_with_na:\n",
        "    print(\"No missing values found in the selected features.\")\n",
        "else:\n",
        "    # Print the feature name and the percentage of missing values\n",
        "    for feature in features_with_na:\n",
        "        print(feature, np.round(train_dataset[feature].isnull().mean(), 4), ' % missing values')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZipW4MOAE4E"
      },
      "source": [
        "If all features have numerical data types, it will print \"All features have numerical values.\" Otherwise, it will print \"Not all features have numerical values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAA1rOX1AGIG",
        "outputId": "2343fa12-7fb9-4aa6-d0ef-05c6bf03d7c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All selected features have numerical values.\n"
          ]
        }
      ],
      "source": [
        "# Exclude the last 4 columns (labels )from checking\n",
        "columns_to_check = train_dataset.columns[:-4]\n",
        "\n",
        "# Check if all selected features have numerical values\n",
        "all_features_numerical = all(train_dataset[feature].dtype != 'O' for feature in columns_to_check)\n",
        "\n",
        "if all_features_numerical:\n",
        "    print(\"All selected features have numerical values.\")\n",
        "else:\n",
        "    print(\"Not all selected features have numerical values.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plotting Missing Values in Labels"
      ],
      "metadata": {
        "id": "pn46ZPT-xm37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and labels\n",
        "features = train_dataset.iloc[:, :256]\n",
        "labels = train_dataset.iloc[:, -4:]\n",
        "\n",
        "# Calculate missing values in labels\n",
        "missing_values = labels.isnull().sum()\n",
        "\n",
        "# Plot missing values\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=missing_values.index, y=missing_values.values)\n",
        "plt.title('Missing Values in Labels')\n",
        "plt.xlabel('Label Columns')\n",
        "plt.ylabel('Number of Missing Values')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "RqDuHK_oxsBJ",
        "outputId": "49212ba7-c9dc-451b-fad9-42d2b29031cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0o0imgJGANdP"
      },
      "source": [
        "# Representation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecA90iZXASN5"
      },
      "source": [
        "**Labels** and **Features**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEKsSpnlAcKh"
      },
      "outputs": [],
      "source": [
        "LABELS = [f'label_{i}' for i in range(1, 5)]\n",
        "FEATURES = [f'feature_{i}' for i in range(1, 257)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing Techniques\n",
        "In scikit-learn (sklearn), the StandardScaler is a preprocessing technique used to standardize features by removing the mean and scaling them to unit variance. This can be important for some machine learning algorithms that are sensitive to the scale of input features."
      ],
      "metadata": {
        "id": "ZLxb3fMeFmOH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "X_train_scaled={}\n",
        "X_valid_scaled={}\n",
        "Y_train_scaled={}\n",
        "Y_valid_scaled={}\n",
        "X_test_scaled={}\n",
        "Y_test_scaled={}\n",
        "\n",
        "for target_Label in LABELS:\n",
        "    tr_d = train_dataset[train_dataset['label_2'].notna()] if target_Label == 'label_2' else train_dataset\n",
        "    val_d = valid_dataset[valid_dataset['label_2'].notna()] if target_Label == 'label_2' else valid_dataset\n",
        "    test_d= test_dataset\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    # Fit the scaler on the training data and transform both training and validation data\n",
        "    X_train_scaled[target_Label]  = pd.DataFrame(scaler.fit_transform(tr_d.drop(LABELS, axis=1)), columns=FEATURES)\n",
        "    Y_train_scaled[target_Label] =  tr_d[target_Label]\n",
        "    X_valid_scaled[target_Label]  = pd.DataFrame(scaler.transform(val_d.drop(LABELS, axis=1)), columns=FEATURES)\n",
        "    Y_valid_scaled[target_Label] =  val_d[target_Label]\n",
        "    X_test_scaled[target_Label] = pd.DataFrame(scaler.fit_transform(test_d.drop(LABELS, axis=1)), columns=FEATURES)\n",
        "    Y_test_scaled[target_Label] = test_d[target_Label]"
      ],
      "metadata": {
        "id": "USCPxFa7F2xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Label 1"
      ],
      "metadata": {
        "id": "dPcUX-eY0KPN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training"
      ],
      "metadata": {
        "id": "PdsJcISTzqvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "classification=svm.SVC(kernel='linear')\n",
        "classification.fit(X_train_scaled['label_1'],Y_train_scaled['label_1'])\n",
        "y_prediction = classification.predict(X_valid_scaled['label_1'])\n",
        "y_pred_test_before = classification.predict(X_test_scaled['label_1'])"
      ],
      "metadata": {
        "id": "qOCBK9ujG9vE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Predicted labels before feature engineering:', y_pred_test_before)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwvyPKTbNHNR",
        "outputId": "d9164351-e292-4289-adcb-c02b24d06dd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted labels before feature engineering: [45 45 45 45 45 45  5  5  5  5 14  5  5  5  5  5  5  5 60 60 60 60 60 60\n",
            " 60 60 19 19 19 19 19 19 19 19 19 19 39 19 19 19 19 19 11 11 11 11 11 11\n",
            " 11 11 11 11 11 11 52 52 52 52 52 52 52 52 52 52 52 25 25 25 25 25 25 24\n",
            " 25 25 25 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 51\n",
            " 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 35 35 35 35 35 35 35 35\n",
            " 56 56 56 56 56 56 56 56 56 56 56 53 53 53 53 53 53 22 53 53 53  3  3  3\n",
            "  3  3  3  3  3  3  3 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 43 43\n",
            " 43 43 43 43 43 43 43 43 43 58 58 58 58 58 58 58 58 44 44 44 44 44 44 44\n",
            " 44 44 44 44 44 44 44 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
            " 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 17 17 17 17 17 17 17\n",
            " 17 17 17 17 17 17  2  2  2  2  2  2  2  2  2  2  2  2 47 47 47 47 47 47\n",
            " 47 47 47 58 47 47 47 54 54 54 54 54 54 54 54 54 54 54 21 21 21 21 21 21\n",
            " 21 21 21 21 21 21 34 34 34 34 34 34 34 34 34 23 23 23 23 23 23 23 23 23\n",
            " 23 23 23 23 10 10 10 10 10 10 10 10 10 10 10 28 28 28 28 28 28 28 28 28\n",
            " 28 28 28 28 28 28 20 20 20 20 20 20 20 20 20 20 20 20  7  7  7  7  7  7\n",
            "  7  7  7  7  6  6  6  6  6  6  6  6  6  6  6  6  4  4  4  4  4  4  4  4\n",
            "  4  4 48 48 48 48 48 48 48 48 48 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
            " 32 32 32 12 12 12 12 12 12 12 12 22 22 22 22 22 22 22 22 22 22 22 22 22\n",
            " 38 38 38 38 38 38 38 38 38 38 38 38 38 36 36 36 36 36 36 36 36 36 36 36\n",
            " 36 36 36 36 59 59 59 59 59 59 59 59 59 59 59 50 50 50 50 50 50 50 50 50\n",
            " 50 50 50 50 50 50 50 50 50 50 50 50 14 14 14 14 14 14 14 15 15 15 15 15\n",
            " 15 15 15 15 15 15 15 24 24 24 24 24 24 13 13 13 13 13 13 13 13 13 13 13\n",
            " 13 29 29 29 29 29 29 25 29 29 29 51 29 29 29 29 29 18 18 18 18 18 18 18\n",
            " 18 18 18 18 18 18 18 18 18  1  1  1  1  1  1  1  1  1  1  9  9  9  9  9\n",
            "  9  9  9  9 49 49 49 49 49 49 49 49 49 49 49 27 27 27 27 27 27 27 27 27\n",
            " 27 27 27 27 27 42 42 42 42 42 42 42 42 42 26 26 26 26 26 26 26 26 26 26\n",
            " 41 41 41 41 41 41 41 41 41 41 57 57 57 57 57 57 57 57 57 57 57 57 57 57\n",
            " 57 57 57  8  8  8  8  8  8  8  8  8  8  8  8  8  8 35 33 33 33 33 33 33\n",
            " 33 33 33 33 33 33 33 33 33 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n",
            " 31 31 31 31 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 30\n",
            " 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 39 39 39 39 39 39 39 39 39\n",
            " 39 39 39 39 39 39]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "aoxwcwP5zt71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.confusion_matrix( Y_valid_scaled['label_1'] ,y_prediction))"
      ],
      "metadata": {
        "id": "uI1a1UleZ5Uk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "360c5e71-81d7-4f03-a851-910ca29ef15e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[12  0  0 ...  0  0  0]\n",
            " [ 0  9  0 ...  0  0  0]\n",
            " [ 0  0 12 ...  0  0  0]\n",
            " ...\n",
            " [ 0  0  0 ... 20  0  0]\n",
            " [ 0  0  0 ...  0 10  0]\n",
            " [ 0  0  0 ...  0  0 10]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (metrics.precision_score( Y_valid_scaled['label_1'] ,y_prediction,average='weighted'))"
      ],
      "metadata": {
        "id": "snDhP4pgbGm2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29e101a2-a711-4d08-ea0c-f6f7101fda8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.98180495985496\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (metrics.accuracy_score( Y_valid_scaled['label_1'] ,y_prediction))"
      ],
      "metadata": {
        "id": "0uI-3DB1awj2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac1b58da-5d52-4e34-cb4d-3d2231a994e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (metrics.recall_score( Y_valid_scaled['label_1'] ,y_prediction,average='weighted'))"
      ],
      "metadata": {
        "id": "Ps6pm3ipbAp5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c543875d-123c-40c5-e38c-44dc714502cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Applying Feature Selection Techniques"
      ],
      "metadata": {
        "id": "XEQW-bNlb7rC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Univariate feature selection\n",
        "\n",
        "Univariate feature selection works by selecting the best features based on univariate statistical tests. It can be seen as a preprocessing step to an estimator."
      ],
      "metadata": {
        "id": "CKlxKcPncTJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest,f_classif\n",
        "selector = SelectKBest(f_classif,k=75)\n",
        "X_new_f1 = selector.fit_transform(X_train_scaled['label_1'],Y_train_scaled['label_1'])\n",
        "print ('New Shape according to the feature selection technique 1', X_new_f1.shape )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BWzOospcXka",
        "outputId": "ee1c0c63-8578-418d-f1b3-b0d5e25419b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Shape according to the feature selection technique 1 (28520, 75)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then try to train the model with new feature count and see the difference.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-TyrRLq9gLKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classification=svm.SVC(kernel='linear')\n",
        "classification.fit(X_new_f1,Y_train_scaled['label_1'])\n",
        "y_prediction = classification.predict(selector.transform(X_valid_scaled['label_1']))\n",
        "y_test_prediction = classification.predict(selector.transform(X_test_scaled['label_1']))\n",
        "print(y_test_prediction)\n"
      ],
      "metadata": {
        "id": "zP6b600vgSyJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b28429aa-7d41-405a-f2ea-eb04e3cbac0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[45 45 45 45 45 45  5  5  5  5  5  5  5  5  5  5  5  5 60 60 60 60 60 60\n",
            " 60 60 19 19 19 19 19 19 19 19 19  6 19 19 19 19 19 19 11 11 11 11 11 11\n",
            " 11 11 11 11 11 11 52 36 52 52 52 52 52 52 52 52 52 25 25 25 25 25 25 25\n",
            " 25 25 25 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 51\n",
            " 40 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 35 35 35 35 35 35 35 35\n",
            " 56 56 56 56 56 56 56 56 56 56 56 53 53 53 53 53 53 53 53 53 53  3  3  3\n",
            "  3  3  3  3  3  3  3 40 40 40 40 40 40 40 20 40 40 40 40 40 40 40 43 43\n",
            " 43 43 43 43 43 43 43 43 43 58 58 47 58 58 58 58 58 44 44 44 44 44 44 44\n",
            " 44 44 44 44 44 44 44 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
            " 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 17 17 17 17 17  1 17\n",
            " 17 17 17 17 17 17  2  2  2  2 14  2  2  2  2  2  2  2 47 47 47 47 47 47\n",
            " 47 47 47 43 47 47 47 54 54 54 54 46 54 54 54 54 54 54 21 21 21 21 21 21\n",
            " 21 21 21 21 21 21 34 34 34 34 34 34 34 34 34 23 23 23 23 23 23 23 23 23\n",
            " 23 23 23 23 10 10 10 10 10 10 10 10 10 10 10 28 28 28 28 28 28 28 28 28\n",
            " 28 28 28 28 28 28 20 20 20 20 20 20 20 20 20 20 20 20  7  7  7  7  7  7\n",
            "  7  7  7  7  6  6  6  6  6  6  6  6  6  6  6  6  4  4  4  4  4  4  4  4\n",
            "  4  4 48 48 48 48 48 48 48 48 48 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
            " 32 32 32 12 12 12 12 12 12 12 12 22 22 22 22 22 22 22 22 22 22 22 22 22\n",
            " 38 38 38 38 38 38 38 38 38 38 38 38 38 36 36 36 36 36 36 47 36 36 36 36\n",
            " 36 36 36 36 59 59 59 59 59 59 59 59 59 59 59 50 50 37 50 50 50 50 50 50\n",
            " 50 50 50 50 50 50 50 50 50 50 50 50 14 14 14 14 14 14 15 15 15 15 15 15\n",
            " 15 15 15 15 15 15 15 24 24 24 24 24 24 13 13 13 13 13 13 13 13 13 13 13\n",
            " 13 29 29 29 23 23 29 25 29 29 14 29 29 29 29 29 29 18 18 18 18 18 18 18\n",
            " 18 18 18 18 18 18 18 18 18  1  1  1  1  1  1  1  1  1  1  9  9  9  9  9\n",
            "  9  9  9  9 49 49 49 49 49 49 49 49 49 49 49 27 27 27 27 27 27 27 27 27\n",
            " 27 27 27 27 27 42 42 42 42 42 42 42 42 42 26 26 26 26 26 26 26 26 26 26\n",
            " 41 41 41 41 41 14 41 41 41 41 57 57 57 57 57 57 57 57 57 57 57 57 57 57\n",
            " 57 57 57  8  8  8  8  4  8  8  8  8  8  8  8  8  8 35 33 33 33 33 33 33\n",
            " 33 33 33 33 33 33 38 33 33 13 31 31 31 31 31 31 31 31 31 31 37 31 31 31\n",
            " 31 31 31 31 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 30\n",
            " 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 39 39 39 39 39 39 39 39 39\n",
            " 39  4 33 39 39 39]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.confusion_matrix( Y_valid_scaled['label_1'] ,y_prediction))"
      ],
      "metadata": {
        "id": "6CorpHH3hx_u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "582b1b34-fa87-483d-d9de-77cd3454c4f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[11  0  0 ...  0  0  0]\n",
            " [ 0  7  0 ...  0  0  0]\n",
            " [ 0  0 12 ...  0  0  0]\n",
            " ...\n",
            " [ 0  0  0 ... 19  0  0]\n",
            " [ 0  0  0 ...  0 10  0]\n",
            " [ 0  0  0 ...  1  0  9]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (metrics.precision_score( Y_valid_scaled['label_1'] ,y_prediction,average='weighted'))"
      ],
      "metadata": {
        "id": "QfK3oXBThx_y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f22ea5a8-1400-493f-cb87-208749ab4666"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9736650570275958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (metrics.accuracy_score( Y_valid_scaled['label_1'] ,y_prediction))"
      ],
      "metadata": {
        "id": "jO9NMuYAhx_y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "561b9ba4-3b59-4081-e423-aa68e1e3f5e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (metrics.recall_score( Y_valid_scaled['label_1'] ,y_prediction,average='weighted'))"
      ],
      "metadata": {
        "id": "84QecOnHhx_z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2c64c6c-b1bd-449a-bb15-eefaa2d25951"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print ('precision:',metrics.precision_score( Y_valid_scaled['label_1'] ,y_prediction,average='weighted'))\n",
        "print ('accuracy: ',metrics.accuracy_score( Y_valid_scaled['label_1'] ,y_prediction))\n",
        "print ('recall:', metrics.recall_score( Y_valid_scaled['label_1'] ,y_prediction,average='weighted'))\n"
      ],
      "metadata": {
        "id": "HPP4uNSqjRpv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a2e3fa1-e6a1-46f0-d2ff-60ec993f212b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision: 0.9736650570275958\n",
            "accuracy:  0.972\n",
            "recall: 0.972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to this feature selection method  to streamline model managed to reduce the feature count from 256 to 100. However, this reduction was accompanied by a slight dip in the model's accuracy. This decline can be traced back to the careful selection of pertinent features and the omission of less impactful ones during the feature selection process. Unfortunately, this might have unintentionally led to the exclusion of certain information that was contributing to the original model's accuracy.\n",
        "\n",
        "The primary goal of feature selection is to refine the model by excluding irrelevant or redundant features, but it's vital to acknowledge that the interactions between features also play a pivotal role in the model's performance. By decreasing the feature count, I may have inadvertently removed critical interactions that were essential for accurate predictions.\n",
        "\n",
        "Another important consideration is the possibility of noise or unnecessary complexity introduced by some features. The removal of such features was aimed at enhancing generalization, which is particularly advantageous when dealing with extensive sets of features. However, it's crucial to strike a balance, as an excessive removal of features could lead the model to oversimplify and miss the intricate nuances in the data, ultimately resulting in reduced accuracy.\n"
      ],
      "metadata": {
        "id": "ODlIjGbWi8ql"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### sklearn.decomposition.PCA"
      ],
      "metadata": {
        "id": "JuvU1mf1jwdc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear dimensionality reduction using Singular Value Decomposition of the data to project it to a lower dimensional space. The input data is centered but not scaled for each feature before applying the SVD."
      ],
      "metadata": {
        "id": "5Uyul3bFkBbY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=0.88,svd_solver='full')\n",
        "pca.fit(X_train_scaled['label_1'])\n",
        "x_train_transformation= pd.DataFrame(pca.transform(X_train_scaled['label_1']))\n",
        "x_valid_transformation= pd.DataFrame(pca.transform(X_valid_scaled['label_1']))\n",
        "x_test_transformation= pd.DataFrame(pca.transform(X_test_scaled['label_1']))\n",
        "x_test_transformation_pass= pca.transform(X_test_scaled['label_1'])\n",
        "print ('New Shape according to the feature selection technique 1', x_train_transformation.shape )\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbQnRJuUkNvi",
        "outputId": "636cbb2f-a148-437a-becf-c5a5c4fb2e79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Shape according to the feature selection technique 1 (28520, 44)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then try to train the model with new feature count and see the difference."
      ],
      "metadata": {
        "id": "f5uLeCqCpcZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classification=svm.SVC(kernel='linear')\n",
        "classification.fit(x_train_transformation,Y_train_scaled['label_1'])\n",
        "y_prediction = classification.predict(x_valid_transformation)\n",
        "y_pred_test_after = classification.predict(x_test_transformation)\n",
        "print('Predicted labels after feature engineering:', y_pred_test_after)"
      ],
      "metadata": {
        "id": "FFxiUqLOpjHX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c85dbd3-9cba-414f-a8ff-ac2beb4f9d2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted labels after feature engineering: [45 45 45 45 45 45  5  5  5  5  7  5  5  5  5  5  5  5 60 60 60 60 60 60\n",
            " 60 60 19 19 19 19 19 19 19 19 19 19 39 19 19 19 19 19 11 11 11 11 11 11\n",
            " 11 11 11 11 11 11 52 36 52 52 52 52 52 52 52 52 52 25 25 25 25 25 25 25\n",
            " 25 25 25 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 51\n",
            " 40 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 35 29 35 35 35 35 35 35\n",
            " 56 56 56 56 56 56 56 56 56 56 56 53 53 53 53 53 53 50 53 53 53  3  3  3\n",
            "  3  3  3  3  3  3  3 40 40 40 40 40 40 40 20 40 40 40 40 40 40 40 43 58\n",
            " 43 43 43 43 43 43 43 43 43 58 58 58 58 58 58 58 58 44 44 44 44 44 44 44\n",
            " 44 44 44 44 44 44 44 37 37 37 37 37 37 37 37 37 37 37 37 20 37 37 37 37\n",
            " 55 55 55 55 55 55 55 55 55 55 55 39 55 55 55 55 55 17  2 17 24 17 17 17\n",
            " 17 17 17 17 17 15  2  2 19  2 18  2  2  2  2  2  2  2 47 47 47 47 47 47\n",
            " 47 47 47 26 47 47 47 54 54 54 54 46 53 54 54 54 54 54 21 21 21 21 21 21\n",
            " 21 21 21 21 21 21 34 27 34 34 34 34 34 34 34 23 23 23 23 23 23 23 23 23\n",
            " 23 23 23 23 10 18 10 10 10 10 10 10 10 10 10 28 28 28 28 28 28 28 28 28\n",
            " 28 28 28 28 28 28 20 20 20 20 20 20 20 20 20 20 20 20  7  7  7  7  7  7\n",
            "  7  7  7  7  6  6  6  6  6  6  6  6  6  6  6  6  4 14  4  4  4  4  4  4\n",
            "  4  4 48 48 48 48 48 48 48 48 48 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
            " 32 32 32 12 12 12 12 12 12 12 12 22 22 22 22 22 22 22 22 22 22 22 22 22\n",
            " 38 38 38 38 38 38 38 38 38 38 11 38 38 36 36 36 36 36 36 47 36 36 36 36\n",
            " 36 36 36 36 59 59 59 59 59 59 59 59 59 59 59 50 50 27 50 50 50 23 50 50\n",
            " 50 50 50 50 50 50 50 50 50 50 50 50 14 14 14 16 14 14 18 15 15 15 15 15\n",
            " 15 15 15 15 15 15 15 24 17 24 24 24 24 13 13 13 13 13 13 13 13 13 13 13\n",
            " 13 29 29 29 23 29 29 25 29 29 14 51 29 29 29 29 29 10 18 18 18 18 18 18\n",
            " 18 18 18 18 18 18 18 18 18  1  1  1  1  1  1  1  1  1  1  9  9  9  9  9\n",
            "  9  9  9  9 49 24 49 49 24 49 49 49 49 49 49 27 27 27 27 27 27 27 27 27\n",
            " 27 27 27 27 27 42 42 42 42 42 20 42 42 42 26 26 26 26 26 26 26 26 26 26\n",
            " 41 41 41 41 41 14 41 41 41 41 57 57 57 57 57 57 57 57 57 57 57 57 57 57\n",
            " 57 57 57  8  8  8  8  8  8  8  8  8  8  8  8  8  8 33 33 33 33 20 33 33\n",
            " 33 33 33 33 33 33 33 33 33 55 31 31 31 31 31 31 31 31 31 31 31 31 17 31\n",
            " 31 31 31 31 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 30\n",
            " 30 30 30 30 30 30 30 30 29 30 30 30 30 30 30 39 39 39 39 39 39 39 39 39\n",
            " 39  2 39 39 39 39]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_df = pd.DataFrame({\n",
        "    'Predicted labels before feature engineering': y_pred_test_before,\n",
        "    'Predicted labels after feature engineering': y_pred_test_after,\n",
        "    'No. of new features': x_test_transformation_pass.shape[1]\n",
        "})\n",
        "\n",
        "\n",
        "for i in range(x_test_transformation_pass.shape[1]):\n",
        "  output_df[f'New feature {i+1}'] = x_test_transformation_pass[:, i]\n",
        "\n",
        "output_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "8wl107kJOk79",
        "outputId": "cab68ea8-d93e-42bf-da7e-fb2d255b0603"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Predicted labels before feature engineering  \\\n",
              "0                                           45   \n",
              "1                                           45   \n",
              "2                                           45   \n",
              "3                                           45   \n",
              "4                                           45   \n",
              "\n",
              "   Predicted labels after feature engineering  No. of new features  \\\n",
              "0                                          45                   44   \n",
              "1                                          45                   44   \n",
              "2                                          45                   44   \n",
              "3                                          45                   44   \n",
              "4                                          45                   44   \n",
              "\n",
              "   New feature 1  New feature 2  New feature 3  New feature 4  New feature 5  \\\n",
              "0      -2.031041       7.072996      -3.899170      -1.139218      -6.607480   \n",
              "1      -6.757219       9.020226      -0.445499     -10.395753      -4.692880   \n",
              "2      -4.869828       3.637857      -0.251019      -5.658368      -2.325319   \n",
              "3      -2.185382       6.080549      -1.050191      -0.983411       2.460842   \n",
              "4       0.699202       6.304911       1.514615      -3.189496      -2.997243   \n",
              "\n",
              "   New feature 6  New feature 7  New feature 8  New feature 9  New feature 10  \\\n",
              "0      -1.029961       3.773949       2.677365       6.098684        1.982514   \n",
              "1       2.287994      -1.798454       2.344746      -2.620985        7.354878   \n",
              "2      -1.254303      -0.189561      -0.317199      -5.770944        4.860928   \n",
              "3       4.478364       0.687827       0.340539       1.508543        6.158429   \n",
              "4      -1.164269       1.858609       3.491644       0.830667        7.437580   \n",
              "\n",
              "   New feature 11  New feature 12  New feature 13  New feature 14  \\\n",
              "0        4.271610       -0.406518       -0.540450       -3.835481   \n",
              "1       -0.439397       -1.280962       -2.865353       -0.332620   \n",
              "2        2.908031       -0.782643       -1.435120       -3.528007   \n",
              "3        3.231875        3.770242        2.019773       -3.831132   \n",
              "4       -0.771613        1.720614        0.374078       -1.453283   \n",
              "\n",
              "   New feature 15  New feature 16  New feature 17  New feature 18  \\\n",
              "0        0.779858       -2.234409        0.416891        1.855999   \n",
              "1       -3.267785        3.044503       -2.110337       -2.286687   \n",
              "2       -1.247274        1.017284        2.006186        0.131780   \n",
              "3        1.881271        1.483123       -2.009631       -2.891516   \n",
              "4        0.912510       -1.763192       -1.246238        0.292901   \n",
              "\n",
              "   New feature 19  New feature 20  New feature 21  New feature 22  \\\n",
              "0       -2.593841       -0.777323       -1.372895        1.763319   \n",
              "1       -1.466394       -1.599279        0.393073        3.609559   \n",
              "2       -1.293697       -2.652614       -0.442117        3.247119   \n",
              "3        3.055495       -2.692857       -0.153073        1.404473   \n",
              "4       -1.563358       -0.790820       -1.679885        4.156949   \n",
              "\n",
              "   New feature 23  New feature 24  New feature 25  New feature 26  \\\n",
              "0       -0.558357       -3.118723       -2.326503        0.724986   \n",
              "1       -0.204600       -2.513195       -2.702389        1.877266   \n",
              "2        0.056819       -5.288655       -1.799017        0.439549   \n",
              "3       -0.204970       -6.016035        0.011836       -1.896885   \n",
              "4        0.301556        0.254043        1.128256        1.104217   \n",
              "\n",
              "   New feature 27  New feature 28  New feature 29  New feature 30  \\\n",
              "0        1.451095       -1.011355       -2.530412        1.979696   \n",
              "1       -2.680341        0.495570        0.172885        0.224661   \n",
              "2       -2.490127        1.684036        0.167060        1.223364   \n",
              "3        0.218005        1.522549       -2.892885        1.143720   \n",
              "4       -0.827386        0.686154        1.817153        2.380075   \n",
              "\n",
              "   New feature 31  New feature 32  New feature 33  New feature 34  \\\n",
              "0        1.353403        0.300167        2.737875        2.935505   \n",
              "1        0.945643        0.240523       -0.889786        0.383714   \n",
              "2        2.511806       -0.065658       -0.749571       -1.029651   \n",
              "3        1.264005       -1.138008       -2.420727       -2.088253   \n",
              "4       -0.552908        0.795972       -1.427992        0.447777   \n",
              "\n",
              "   New feature 35  New feature 36  New feature 37  New feature 38  \\\n",
              "0       -0.935346       -1.454484       -0.471733        2.441985   \n",
              "1       -0.602832       -1.553723       -1.209518        0.948211   \n",
              "2       -1.081592       -1.382162       -0.782291        0.076146   \n",
              "3       -1.291993       -0.584451       -2.098503        0.148559   \n",
              "4       -0.112454       -0.795440       -1.952042        0.524060   \n",
              "\n",
              "   New feature 39  New feature 40  New feature 41  New feature 42  \\\n",
              "0       -1.187771       -0.387655       -0.386766        0.573784   \n",
              "1       -0.729147       -0.962219       -0.775931       -1.569257   \n",
              "2        0.992883       -0.258094       -0.705611        0.900671   \n",
              "3        1.161322       -2.600385        0.400560        0.977827   \n",
              "4        0.007208        2.851649        0.776596        0.756446   \n",
              "\n",
              "   New feature 43  New feature 44  \n",
              "0        2.539350       -0.666926  \n",
              "1        0.893573        0.399989  \n",
              "2        0.309704        1.042084  \n",
              "3       -0.855402       -0.446161  \n",
              "4       -0.818649       -2.182648  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8c71db8a-b8a9-4d25-b4f2-e79179854358\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted labels before feature engineering</th>\n",
              "      <th>Predicted labels after feature engineering</th>\n",
              "      <th>No. of new features</th>\n",
              "      <th>New feature 1</th>\n",
              "      <th>New feature 2</th>\n",
              "      <th>New feature 3</th>\n",
              "      <th>New feature 4</th>\n",
              "      <th>New feature 5</th>\n",
              "      <th>New feature 6</th>\n",
              "      <th>New feature 7</th>\n",
              "      <th>New feature 8</th>\n",
              "      <th>New feature 9</th>\n",
              "      <th>New feature 10</th>\n",
              "      <th>New feature 11</th>\n",
              "      <th>New feature 12</th>\n",
              "      <th>New feature 13</th>\n",
              "      <th>New feature 14</th>\n",
              "      <th>New feature 15</th>\n",
              "      <th>New feature 16</th>\n",
              "      <th>New feature 17</th>\n",
              "      <th>New feature 18</th>\n",
              "      <th>New feature 19</th>\n",
              "      <th>New feature 20</th>\n",
              "      <th>New feature 21</th>\n",
              "      <th>New feature 22</th>\n",
              "      <th>New feature 23</th>\n",
              "      <th>New feature 24</th>\n",
              "      <th>New feature 25</th>\n",
              "      <th>New feature 26</th>\n",
              "      <th>New feature 27</th>\n",
              "      <th>New feature 28</th>\n",
              "      <th>New feature 29</th>\n",
              "      <th>New feature 30</th>\n",
              "      <th>New feature 31</th>\n",
              "      <th>New feature 32</th>\n",
              "      <th>New feature 33</th>\n",
              "      <th>New feature 34</th>\n",
              "      <th>New feature 35</th>\n",
              "      <th>New feature 36</th>\n",
              "      <th>New feature 37</th>\n",
              "      <th>New feature 38</th>\n",
              "      <th>New feature 39</th>\n",
              "      <th>New feature 40</th>\n",
              "      <th>New feature 41</th>\n",
              "      <th>New feature 42</th>\n",
              "      <th>New feature 43</th>\n",
              "      <th>New feature 44</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>45</td>\n",
              "      <td>45</td>\n",
              "      <td>44</td>\n",
              "      <td>-2.031041</td>\n",
              "      <td>7.072996</td>\n",
              "      <td>-3.899170</td>\n",
              "      <td>-1.139218</td>\n",
              "      <td>-6.607480</td>\n",
              "      <td>-1.029961</td>\n",
              "      <td>3.773949</td>\n",
              "      <td>2.677365</td>\n",
              "      <td>6.098684</td>\n",
              "      <td>1.982514</td>\n",
              "      <td>4.271610</td>\n",
              "      <td>-0.406518</td>\n",
              "      <td>-0.540450</td>\n",
              "      <td>-3.835481</td>\n",
              "      <td>0.779858</td>\n",
              "      <td>-2.234409</td>\n",
              "      <td>0.416891</td>\n",
              "      <td>1.855999</td>\n",
              "      <td>-2.593841</td>\n",
              "      <td>-0.777323</td>\n",
              "      <td>-1.372895</td>\n",
              "      <td>1.763319</td>\n",
              "      <td>-0.558357</td>\n",
              "      <td>-3.118723</td>\n",
              "      <td>-2.326503</td>\n",
              "      <td>0.724986</td>\n",
              "      <td>1.451095</td>\n",
              "      <td>-1.011355</td>\n",
              "      <td>-2.530412</td>\n",
              "      <td>1.979696</td>\n",
              "      <td>1.353403</td>\n",
              "      <td>0.300167</td>\n",
              "      <td>2.737875</td>\n",
              "      <td>2.935505</td>\n",
              "      <td>-0.935346</td>\n",
              "      <td>-1.454484</td>\n",
              "      <td>-0.471733</td>\n",
              "      <td>2.441985</td>\n",
              "      <td>-1.187771</td>\n",
              "      <td>-0.387655</td>\n",
              "      <td>-0.386766</td>\n",
              "      <td>0.573784</td>\n",
              "      <td>2.539350</td>\n",
              "      <td>-0.666926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>45</td>\n",
              "      <td>45</td>\n",
              "      <td>44</td>\n",
              "      <td>-6.757219</td>\n",
              "      <td>9.020226</td>\n",
              "      <td>-0.445499</td>\n",
              "      <td>-10.395753</td>\n",
              "      <td>-4.692880</td>\n",
              "      <td>2.287994</td>\n",
              "      <td>-1.798454</td>\n",
              "      <td>2.344746</td>\n",
              "      <td>-2.620985</td>\n",
              "      <td>7.354878</td>\n",
              "      <td>-0.439397</td>\n",
              "      <td>-1.280962</td>\n",
              "      <td>-2.865353</td>\n",
              "      <td>-0.332620</td>\n",
              "      <td>-3.267785</td>\n",
              "      <td>3.044503</td>\n",
              "      <td>-2.110337</td>\n",
              "      <td>-2.286687</td>\n",
              "      <td>-1.466394</td>\n",
              "      <td>-1.599279</td>\n",
              "      <td>0.393073</td>\n",
              "      <td>3.609559</td>\n",
              "      <td>-0.204600</td>\n",
              "      <td>-2.513195</td>\n",
              "      <td>-2.702389</td>\n",
              "      <td>1.877266</td>\n",
              "      <td>-2.680341</td>\n",
              "      <td>0.495570</td>\n",
              "      <td>0.172885</td>\n",
              "      <td>0.224661</td>\n",
              "      <td>0.945643</td>\n",
              "      <td>0.240523</td>\n",
              "      <td>-0.889786</td>\n",
              "      <td>0.383714</td>\n",
              "      <td>-0.602832</td>\n",
              "      <td>-1.553723</td>\n",
              "      <td>-1.209518</td>\n",
              "      <td>0.948211</td>\n",
              "      <td>-0.729147</td>\n",
              "      <td>-0.962219</td>\n",
              "      <td>-0.775931</td>\n",
              "      <td>-1.569257</td>\n",
              "      <td>0.893573</td>\n",
              "      <td>0.399989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>45</td>\n",
              "      <td>45</td>\n",
              "      <td>44</td>\n",
              "      <td>-4.869828</td>\n",
              "      <td>3.637857</td>\n",
              "      <td>-0.251019</td>\n",
              "      <td>-5.658368</td>\n",
              "      <td>-2.325319</td>\n",
              "      <td>-1.254303</td>\n",
              "      <td>-0.189561</td>\n",
              "      <td>-0.317199</td>\n",
              "      <td>-5.770944</td>\n",
              "      <td>4.860928</td>\n",
              "      <td>2.908031</td>\n",
              "      <td>-0.782643</td>\n",
              "      <td>-1.435120</td>\n",
              "      <td>-3.528007</td>\n",
              "      <td>-1.247274</td>\n",
              "      <td>1.017284</td>\n",
              "      <td>2.006186</td>\n",
              "      <td>0.131780</td>\n",
              "      <td>-1.293697</td>\n",
              "      <td>-2.652614</td>\n",
              "      <td>-0.442117</td>\n",
              "      <td>3.247119</td>\n",
              "      <td>0.056819</td>\n",
              "      <td>-5.288655</td>\n",
              "      <td>-1.799017</td>\n",
              "      <td>0.439549</td>\n",
              "      <td>-2.490127</td>\n",
              "      <td>1.684036</td>\n",
              "      <td>0.167060</td>\n",
              "      <td>1.223364</td>\n",
              "      <td>2.511806</td>\n",
              "      <td>-0.065658</td>\n",
              "      <td>-0.749571</td>\n",
              "      <td>-1.029651</td>\n",
              "      <td>-1.081592</td>\n",
              "      <td>-1.382162</td>\n",
              "      <td>-0.782291</td>\n",
              "      <td>0.076146</td>\n",
              "      <td>0.992883</td>\n",
              "      <td>-0.258094</td>\n",
              "      <td>-0.705611</td>\n",
              "      <td>0.900671</td>\n",
              "      <td>0.309704</td>\n",
              "      <td>1.042084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>45</td>\n",
              "      <td>45</td>\n",
              "      <td>44</td>\n",
              "      <td>-2.185382</td>\n",
              "      <td>6.080549</td>\n",
              "      <td>-1.050191</td>\n",
              "      <td>-0.983411</td>\n",
              "      <td>2.460842</td>\n",
              "      <td>4.478364</td>\n",
              "      <td>0.687827</td>\n",
              "      <td>0.340539</td>\n",
              "      <td>1.508543</td>\n",
              "      <td>6.158429</td>\n",
              "      <td>3.231875</td>\n",
              "      <td>3.770242</td>\n",
              "      <td>2.019773</td>\n",
              "      <td>-3.831132</td>\n",
              "      <td>1.881271</td>\n",
              "      <td>1.483123</td>\n",
              "      <td>-2.009631</td>\n",
              "      <td>-2.891516</td>\n",
              "      <td>3.055495</td>\n",
              "      <td>-2.692857</td>\n",
              "      <td>-0.153073</td>\n",
              "      <td>1.404473</td>\n",
              "      <td>-0.204970</td>\n",
              "      <td>-6.016035</td>\n",
              "      <td>0.011836</td>\n",
              "      <td>-1.896885</td>\n",
              "      <td>0.218005</td>\n",
              "      <td>1.522549</td>\n",
              "      <td>-2.892885</td>\n",
              "      <td>1.143720</td>\n",
              "      <td>1.264005</td>\n",
              "      <td>-1.138008</td>\n",
              "      <td>-2.420727</td>\n",
              "      <td>-2.088253</td>\n",
              "      <td>-1.291993</td>\n",
              "      <td>-0.584451</td>\n",
              "      <td>-2.098503</td>\n",
              "      <td>0.148559</td>\n",
              "      <td>1.161322</td>\n",
              "      <td>-2.600385</td>\n",
              "      <td>0.400560</td>\n",
              "      <td>0.977827</td>\n",
              "      <td>-0.855402</td>\n",
              "      <td>-0.446161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>45</td>\n",
              "      <td>45</td>\n",
              "      <td>44</td>\n",
              "      <td>0.699202</td>\n",
              "      <td>6.304911</td>\n",
              "      <td>1.514615</td>\n",
              "      <td>-3.189496</td>\n",
              "      <td>-2.997243</td>\n",
              "      <td>-1.164269</td>\n",
              "      <td>1.858609</td>\n",
              "      <td>3.491644</td>\n",
              "      <td>0.830667</td>\n",
              "      <td>7.437580</td>\n",
              "      <td>-0.771613</td>\n",
              "      <td>1.720614</td>\n",
              "      <td>0.374078</td>\n",
              "      <td>-1.453283</td>\n",
              "      <td>0.912510</td>\n",
              "      <td>-1.763192</td>\n",
              "      <td>-1.246238</td>\n",
              "      <td>0.292901</td>\n",
              "      <td>-1.563358</td>\n",
              "      <td>-0.790820</td>\n",
              "      <td>-1.679885</td>\n",
              "      <td>4.156949</td>\n",
              "      <td>0.301556</td>\n",
              "      <td>0.254043</td>\n",
              "      <td>1.128256</td>\n",
              "      <td>1.104217</td>\n",
              "      <td>-0.827386</td>\n",
              "      <td>0.686154</td>\n",
              "      <td>1.817153</td>\n",
              "      <td>2.380075</td>\n",
              "      <td>-0.552908</td>\n",
              "      <td>0.795972</td>\n",
              "      <td>-1.427992</td>\n",
              "      <td>0.447777</td>\n",
              "      <td>-0.112454</td>\n",
              "      <td>-0.795440</td>\n",
              "      <td>-1.952042</td>\n",
              "      <td>0.524060</td>\n",
              "      <td>0.007208</td>\n",
              "      <td>2.851649</td>\n",
              "      <td>0.776596</td>\n",
              "      <td>0.756446</td>\n",
              "      <td>-0.818649</td>\n",
              "      <td>-2.182648</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c71db8a-b8a9-4d25-b4f2-e79179854358')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8c71db8a-b8a9-4d25-b4f2-e79179854358 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8c71db8a-b8a9-4d25-b4f2-e79179854358');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-075c7035-a74d-4eb7-aa3c-96b400b6b63b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-075c7035-a74d-4eb7-aa3c-96b400b6b63b')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-075c7035-a74d-4eb7-aa3c-96b400b6b63b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the DataFrame to the specified CSV file path\n",
        "output_df.to_csv(f\"190282X_label_1.csv\", index=False)"
      ],
      "metadata": {
        "id": "orA_wIqeSU5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.confusion_matrix( Y_valid_scaled['label_1'] ,y_prediction))"
      ],
      "metadata": {
        "id": "_jPh6i6tpjHZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0df23472-65c0-432e-9ac9-a2cc1a744508"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  0  0 ...  0  0  0]\n",
            " [ 1 12  0 ...  0  0  0]\n",
            " [ 0  9  0 ...  0  0  0]\n",
            " ...\n",
            " [19  1  0 ...  0  0  0]\n",
            " [ 9  1  0 ...  0  0  0]\n",
            " [10  0  0 ...  0  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (metrics.precision_score( Y_valid_scaled['label_1'] ,y_prediction,average='weighted'))"
      ],
      "metadata": {
        "id": "gqpqqRKypjHc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed80d1fa-751c-4314-eb51-3c4204045ee2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0003449419568822554\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (metrics.accuracy_score( Y_valid_scaled['label_1'] ,y_prediction))"
      ],
      "metadata": {
        "id": "AxLGB-yfpjHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (metrics.recall_score( Y_valid_scaled['label_1'] ,y_prediction,average='weighted'))"
      ],
      "metadata": {
        "id": "HBEZzv9EpjHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"precesion:\",metrics.precision_score( Y_valid_scaled['label_1'] ,y_prediction,average='weighted'))\n",
        "print (\"accracy: \",metrics.accuracy_score( Y_valid_scaled['label_1'] ,y_prediction))\n",
        "print (\"recall: \",metrics.recall_score( Y_valid_scaled['label_1'] ,y_prediction,average='weighted'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MV8wFXGM8Yqy",
        "outputId": "0b037ecc-171a-482a-a108-f1a304013ccd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precesion: 0.9511814327571293\n",
            "accracy:  0.9466666666666667\n",
            "recall:  0.9466666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "noX00tBfqEPl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Label 2"
      ],
      "metadata": {
        "id": "F6Vg7pJePWr9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training"
      ],
      "metadata": {
        "id": "rUeU-Un7PWr_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "# Create a KNN classifier\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=5)  # You can adjust the number of neighbors (k) as needed\n",
        "\n",
        "# Fit the KNN classifier to the training data\n",
        "knn_classifier.fit(X_train_scaled['label_2'], Y_train_scaled['label_2'])\n",
        "\n",
        "# Make predictions using the KNN classifier\n",
        "y_prediction = knn_classifier.predict(X_valid_scaled['label_2'])\n",
        "y_pred_test_before = knn_classifier.predict(X_test_scaled['label_2'])\n",
        "print('Predicted labels before feature engineering:', y_pred_test_before)\n"
      ],
      "metadata": {
        "id": "ox9u3bmEPWsA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2d5db28-4dbf-4a97-e4f2-2bd805835a63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted labels before feature engineering: [26. 31. 31. 27. 31. 27. 25. 25. 25. 25. 25. 25. 25. 25. 25. 25. 25. 25.\n",
            " 27. 27. 27. 27. 27. 27. 27. 27. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23.\n",
            " 23. 23. 26. 23. 23. 23. 33. 33. 33. 33. 33. 33. 33. 33. 33. 33. 33. 33.\n",
            " 34. 34. 34. 34. 34. 34. 34. 34. 34. 34. 34. 22. 22. 22. 22. 22. 22. 22.\n",
            " 22. 22. 22. 30. 30. 30. 30. 30. 30. 30. 30. 30. 30. 30. 30. 30. 30. 30.\n",
            " 30. 30. 30. 30. 30. 26. 26. 26. 26. 26. 26. 26. 26. 26. 26. 26. 26. 26.\n",
            " 26. 26. 26. 26. 24. 24. 24. 24. 24. 24. 24. 24. 24. 24. 24. 24. 24. 24.\n",
            " 24. 24. 24. 24. 24. 24. 24. 24. 24. 24. 24. 24. 33. 24. 24. 31. 31. 31.\n",
            " 31. 31. 31. 31. 31. 31. 31. 26. 26. 26. 26. 26. 26. 26. 26. 26. 26. 26.\n",
            " 26. 26. 26. 26. 31. 31. 31. 31. 31. 31. 31. 31. 31. 31. 31. 29. 29. 29.\n",
            " 29. 29. 29. 29. 29. 61. 61. 61. 61. 61. 61. 61. 61. 61. 61. 61. 61. 61.\n",
            " 61. 27. 27. 27. 27. 27. 27. 27. 27. 27. 27. 27. 27. 31. 27. 27. 27. 27.\n",
            " 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 26.\n",
            " 26. 26. 26. 26. 26. 26. 26. 26. 26. 26. 26. 26. 25. 25. 25. 25. 25. 25.\n",
            " 25. 25. 25. 25. 25. 25. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23.\n",
            " 23. 27. 27. 27. 27. 27. 27. 27. 27. 27. 27. 27. 26. 26. 26. 27. 26. 26.\n",
            " 26. 26. 26. 26. 26. 26. 25. 25. 25. 25. 25. 25. 25. 25. 25. 28. 28. 28.\n",
            " 28. 28. 28. 28. 28. 28. 28. 28. 28. 28. 36. 36. 36. 36. 36. 36. 36. 36.\n",
            " 36. 36. 36. 28. 28. 28. 28. 28. 28. 28. 28. 28. 28. 28. 28. 28. 28. 28.\n",
            " 25. 25. 25. 25. 25. 25. 25. 25. 25. 25. 25. 25. 27. 27. 27. 27. 27. 27.\n",
            " 27. 27. 27. 27. 25. 25. 25. 25. 25. 25. 25. 25. 25. 25. 25. 25. 23. 23.\n",
            " 23. 23. 23. 23. 23. 23. 23. 23. 26. 26. 26. 26. 26. 26. 26. 26. 26. 23.\n",
            " 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 26. 26. 26.\n",
            " 26. 26. 26. 26. 26. 33. 33. 33. 33. 33. 33. 33. 33. 33. 33. 33. 33. 33.\n",
            " 32. 32. 32. 32. 32. 32. 32. 32. 32. 32. 32. 32. 32. 22. 22. 22. 22. 22.\n",
            " 22. 22. 22. 22. 22. 22. 22. 22. 22. 22. 31. 31. 31. 31. 31. 31. 31. 31.\n",
            " 31. 31. 31. 24. 24. 31. 24. 24. 24. 24. 24. 24. 24. 24. 24. 24. 24. 24.\n",
            " 24. 24. 24. 24. 24. 24. 31. 31. 31. 31. 31. 31. 25. 28. 28. 28. 28. 28.\n",
            " 28. 28. 28. 28. 28. 28. 28. 26. 26. 26. 26. 26. 26. 27. 27. 27. 27. 27.\n",
            " 27. 27. 27. 27. 27. 27. 27. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23.\n",
            " 23. 23. 23. 23. 23. 25. 25. 25. 25. 25. 25. 25. 25. 25. 25. 25. 25. 25.\n",
            " 25. 25. 25. 30. 30. 30. 30. 30. 30. 30. 30. 30. 30. 35. 35. 35. 35. 35.\n",
            " 35. 35. 35. 35. 26. 26. 26. 26. 26. 26. 26. 26. 26. 26. 26. 31. 31. 31.\n",
            " 31. 31. 31. 31. 31. 31. 31. 31. 31. 31. 31. 29. 29. 29. 29. 29. 29. 29.\n",
            " 29. 29. 22. 22. 22. 22. 22. 22. 22. 22. 22. 22. 30. 30. 30. 30. 30. 30.\n",
            " 30. 30. 30. 30. 27. 27. 27. 27. 27. 27. 27. 27. 27. 27. 27. 27. 27. 27.\n",
            " 27. 27. 27. 41. 41. 41. 41. 41. 41. 41. 41. 41. 41. 41. 41. 41. 41. 26.\n",
            " 26. 26. 26. 26. 26. 26. 26. 26. 26. 26. 26. 26. 26. 26. 26. 23. 26. 26.\n",
            " 26. 26. 26. 26. 26. 26. 26. 26. 26. 26. 26. 26. 26. 26. 26. 26. 30. 30.\n",
            " 30. 30. 30. 30. 30. 30. 30. 30. 30. 30. 30. 30. 30. 30. 30. 30. 30. 28.\n",
            " 28. 28. 28. 28. 28. 28. 28. 28. 28. 28. 28. 28. 28. 28. 28. 29. 29. 29.\n",
            " 29. 29. 29. 29. 29. 29. 29. 29. 29. 29. 26. 29.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tiZRt_wJPWsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.confusion_matrix( Y_valid_scaled['label_2'] ,y_prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0e397af-cc74-40a4-d347-9eb90eeffa61",
        "id": "PW4e6sHlPWsC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 36   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0  70   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0]\n",
            " [  0   1  44   0   0   0   0   0   0   0   0   1   0   0   0   0   0]\n",
            " [  0   0   0  78   0   0   0   0   0   0   0   0   0   0   1   0   0]\n",
            " [  0   0   0   0 115   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0  81   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  46   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  45   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   1   0   1   0  46   0   0   0   0   0   0   0   0]\n",
            " [  0   0   1   0   0   0   0   0   0  64   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   1   0   0   0   0   0  10   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  30   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   1   0   0   0   0   0  10   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  11   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   8   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  14   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  19]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (metrics.precision_score( Y_valid_scaled['label_2'] ,y_prediction,average='weighted'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bdc0189-deca-449e-e047-4bd218583c22",
        "id": "7DrtK9tqPWsC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9880671083222579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (metrics.accuracy_score( Y_valid_scaled['label_2'] ,y_prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a255b58-73f0-4145-c35b-f1d0f76ebbb8",
        "id": "eQr_uJFePWsD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9877717391304348\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (metrics.recall_score( Y_valid_scaled['label_2'] ,y_prediction,average='weighted'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b289c26a-51cd-48a2-9d60-b57f70993ffc",
        "id": "MXGX0GmBPWsE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9877717391304348\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Applying Feature Selection Techniques"
      ],
      "metadata": {
        "id": "NzH5-1iMPWsE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### sklearn.decomposition.PCA"
      ],
      "metadata": {
        "id": "z_4fryBlPWsI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear dimensionality reduction using Singular Value Decomposition of the data to project it to a lower dimensional space. The input data is centered but not scaled for each feature before applying the SVD."
      ],
      "metadata": {
        "id": "lfy1D1TVPWsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=0.75,svd_solver='full')\n",
        "pca.fit(X_train_scaled['label_2'])\n",
        "x_train_transformation= pd.DataFrame(pca.transform(X_train_scaled['label_2']))\n",
        "x_valid_transformation= pd.DataFrame(pca.transform(X_valid_scaled['label_2']))\n",
        "x_test_transformation= pca.transform(X_test_scaled['label_2'])\n",
        "print ('New Shape according to the feature selection technique 1', x_train_transformation.shape )\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78d29900-bca4-4dfa-8de1-90859e9724f6",
        "id": "21dzeGEKPWsJ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Shape according to the feature selection technique 1 (28040, 25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then try to train the model with new feature count and see the difference."
      ],
      "metadata": {
        "id": "JelIeZ1WPWsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "\n",
        "# Create a KNN classifier\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=5)  # You can adjust the number of neighbors (k) as needed\n",
        "\n",
        "# Fit the KNN classifier to the training data\n",
        "knn_classifier.fit(x_train_transformation, Y_train_scaled['label_2'])\n",
        "\n",
        "# Make predictions using the KNN classifier\n",
        "y_prediction = knn_classifier.predict(x_valid_transformation)\n",
        "\n",
        "y_pred_test_after = knn_classifier.predict(x_test_transformation)\n",
        "print('Predicted labels after feature engineering:', y_pred_test_after)\n"
      ],
      "metadata": {
        "id": "c7OfpHxMPWsJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf2655af-313c-4398-b465-dd9e5c396cfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted labels after feature engineering: [26. 31. 27. 27. 31. 23. 25. 25. 25. 25. 25. 25. 25. 25. 25. 25. 25. 25.\n",
            " 27. 27. 27. 27. 27. 27. 27. 27. 23. 23. 23. 23. 23. 25. 23. 23. 23. 23.\n",
            " 23. 23. 26. 23. 23. 23. 33. 33. 33. 33. 33. 33. 33. 33. 33. 33. 33. 33.\n",
            " 34. 22. 34. 34. 34. 34. 34. 34. 34. 34. 34. 22. 22. 22. 22. 22. 22. 22.\n",
            " 22. 22. 22. 30. 30. 30. 30. 30. 30. 30. 30. 30. 30. 30. 30. 30. 30. 30.\n",
            " 30. 30. 30. 30. 30. 26. 26. 26. 26. 26. 26. 26. 26. 26. 26. 26. 26. 26.\n",
            " 26. 26. 26. 26. 24. 24. 24. 24. 24. 24. 24. 24. 24. 24. 24. 24. 24. 24.\n",
            " 24. 24. 24. 24. 24. 24. 24. 24. 24. 24. 24. 24. 33. 24. 24. 31. 31. 31.\n",
            " 31. 31. 31. 31. 31. 31. 31. 26. 26. 26. 26. 26. 26. 26. 26. 26. 26. 26.\n",
            " 26. 26. 26. 26. 31. 31. 31. 31. 31. 34. 31. 31. 31. 31. 31. 29. 29. 29.\n",
            " 29. 29. 29. 29. 29. 61. 61. 61. 61. 61. 61. 61. 61. 61. 61. 61. 61. 61.\n",
            " 61. 27. 27. 27. 27. 27. 27. 27. 27. 27. 27. 27. 27. 31. 27. 27. 27. 27.\n",
            " 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 28. 23. 23. 23. 26. 23. 26.\n",
            " 26. 26. 26. 26. 26. 26. 26. 26. 26. 26. 26. 26. 25. 25. 25. 25. 25. 25.\n",
            " 25. 25. 25. 26. 25. 25. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23.\n",
            " 23. 27. 27. 27. 27. 30. 27. 27. 27. 27. 27. 27. 26. 26. 26. 27. 26. 26.\n",
            " 26. 26. 26. 26. 26. 26. 25. 25. 25. 25. 25. 25. 25. 25. 25. 28. 28. 28.\n",
            " 28. 28. 28. 28. 28. 28. 28. 28. 28. 28. 36. 36. 36. 36. 36. 36. 36. 36.\n",
            " 36. 36. 36. 28. 28. 28. 28. 28. 28. 28. 28. 28. 28. 28. 28. 28. 28. 28.\n",
            " 25. 25. 25. 25. 25. 25. 25. 25. 25. 25. 25. 25. 27. 27. 27. 27. 27. 27.\n",
            " 27. 27. 27. 27. 25. 25. 25. 25. 25. 25. 25. 25. 25. 25. 25. 25. 23. 23.\n",
            " 23. 23. 23. 23. 23. 23. 23. 23. 26. 26. 26. 26. 26. 26. 26. 26. 26. 23.\n",
            " 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 26. 26. 26.\n",
            " 26. 26. 26. 26. 26. 33. 33. 33. 33. 33. 33. 33. 33. 33. 33. 33. 33. 33.\n",
            " 32. 32. 31. 32. 32. 32. 32. 32. 32. 32. 32. 32. 32. 22. 22. 22. 22. 22.\n",
            " 22. 22. 22. 22. 22. 22. 22. 22. 22. 22. 31. 31. 31. 31. 31. 31. 31. 31.\n",
            " 31. 31. 31. 24. 24. 23. 24. 24. 24. 24. 24. 24. 24. 24. 24. 24. 24. 24.\n",
            " 24. 24. 24. 24. 24. 24. 30. 31. 31. 31. 31. 31. 25. 28. 28. 28. 28. 28.\n",
            " 28. 28. 28. 28. 28. 28. 28. 26. 26. 26. 26. 26. 26. 27. 27. 27. 27. 27.\n",
            " 27. 25. 27. 24. 27. 27. 27. 23. 23. 23. 23. 23. 30. 22. 23. 23. 23. 23.\n",
            " 23. 23. 23. 23. 23. 25. 25. 31. 25. 25. 25. 25. 25. 25. 25. 25. 25. 25.\n",
            " 25. 25. 25. 30. 30. 30. 30. 30. 30. 30. 30. 30. 30. 35. 35. 35. 35. 35.\n",
            " 35. 35. 35. 35. 26. 26. 26. 26. 26. 26. 26. 26. 26. 26. 26. 31. 31. 31.\n",
            " 31. 31. 31. 31. 31. 31. 31. 31. 31. 31. 31. 29. 29. 29. 25. 29. 29. 29.\n",
            " 29. 29. 22. 22. 22. 22. 22. 22. 22. 22. 22. 22. 30. 30. 30. 30. 30. 30.\n",
            " 30. 30. 30. 30. 27. 27. 27. 27. 27. 27. 27. 27. 27. 27. 27. 27. 27. 24.\n",
            " 27. 27. 27. 41. 41. 41. 41. 41. 41. 41. 41. 41. 41. 41. 41. 41. 41. 26.\n",
            " 26. 26. 26. 61. 26. 26. 26. 26. 26. 26. 26. 26. 26. 26. 26. 26. 26. 26.\n",
            " 26. 26. 26. 26. 26. 26. 26. 26. 26. 26. 26. 26. 26. 25. 26. 26. 30. 30.\n",
            " 30. 30. 30. 30. 30. 30. 30. 30. 30. 30. 30. 30. 30. 30. 30. 30. 30. 28.\n",
            " 28. 28. 28. 28. 28. 28. 28. 28. 28. 28. 28. 28. 28. 28. 28. 29. 27. 29.\n",
            " 29. 29. 29. 29. 29. 29. 29. 29. 29. 29. 26. 29.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.confusion_matrix( Y_valid_scaled['label_2'] ,y_prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3adee98c-0d4c-49cf-8457-a267dc3fbb86",
        "id": "Orf8SP4mPWsK"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 34   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   0]\n",
            " [  0  69   0   0   1   0   0   0   1   0   0   0   0   0   0   0   0]\n",
            " [  0   0  43   0   0   0   0   1   0   0   0   2   0   0   0   0   0]\n",
            " [  0   0   0  77   1   0   0   0   0   0   0   0   0   0   1   0   0]\n",
            " [  0   0   1   2 110   0   0   0   0   0   0   0   0   0   1   1   0]\n",
            " [  0   1   0   0   1  79   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  46   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   1   0   0   0   0   0  43   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   1   2   0   0   0  45   0   0   0   0   0   0   0   0]\n",
            " [  0   0   1   0   1   0   0   0   1  61   1   0   0   0   0   0   0]\n",
            " [  0   0   0   0   1   0   0   0   0   0  10   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  30   0   0   0   0   0]\n",
            " [  0   0   0   0   0   1   0   0   0   0   0   0  10   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  11   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   8   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  14   0]\n",
            " [  0   0   0   0   0   0   1   0   0   0   0   0   0   0   1   0  17]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (metrics.precision_score( Y_valid_scaled['label_2'] ,y_prediction,average='weighted'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4978c0a-f287-4d4b-8faa-b0043a8ad7b7",
        "id": "tf2W9C8DPWsK"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9620553181192202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (metrics.accuracy_score( Y_valid_scaled['label_2'] ,y_prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af742536-ac9b-46b1-e5d4-702ccc431b16",
        "id": "-T33dEHEPWsK"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9605978260869565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (metrics.recall_score( Y_valid_scaled['label_2'] ,y_prediction,average='weighted'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "904df03b-560a-43d8-8ed1-491738917472",
        "id": "RG-tSLhIPWsL"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9605978260869565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"precision\",metrics.precision_score( Y_valid_scaled['label_2'] ,y_prediction,average='weighted'))\n",
        "print (\"accuracy\",metrics.accuracy_score( Y_valid_scaled['label_2'] ,y_prediction))\n",
        "print (\"recall\",metrics.recall_score( Y_valid_scaled['label_2'] ,y_prediction,average='weighted'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iPMDJzB96-q",
        "outputId": "bd16873f-e1aa-4fe2-b2b0-cb9b99a5b84d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision 0.9620553181192202\n",
            "accuracy 0.9605978260869565\n",
            "recall 0.9605978260869565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_df = pd.DataFrame({\n",
        "    'Predicted labels before feature engineering': y_pred_test_before,\n",
        "    'Predicted labels after feature engineering': y_pred_test_after,\n",
        "    'No. of new features': x_test_transformation.shape[1]\n",
        "})\n",
        "\n",
        "\n",
        "for i in range(x_test_transformation.shape[1]):\n",
        "  output_df[f'New feature {i+1}'] = x_test_transformation[:, i]\n",
        "\n",
        "output_df.head()"
      ],
      "metadata": {
        "id": "_4na1p2zVGQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_df.to_csv(f\"190282X_label_2.csv\", index=False)"
      ],
      "metadata": {
        "id": "Ped8o7gzVoLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QnjTWJnuPWsL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Label 3"
      ],
      "metadata": {
        "id": "p8Oe_grg2cFD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training"
      ],
      "metadata": {
        "id": "LHHKa4sV2cFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "classification=svm.SVC(kernel='linear')\n",
        "classification.fit(X_train_scaled['label_3'],Y_train_scaled['label_3'])\n",
        "y_prediction = classification.predict(X_valid_scaled['label_3'])\n",
        "y_pred_test_before = classification.predict(X_test_scaled['label_3'])\n",
        "print('Predicted labels before feature engineering:', y_pred_test_before)\n"
      ],
      "metadata": {
        "id": "RWL-7xyP2cFS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0805b425-f854-4db4-ba12-91dcd07a6fa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted labels before feature engineering: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1\n",
            " 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tSzZ1LWcWefH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "upSvirpX2cFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.confusion_matrix( Y_valid_scaled['label_3'] ,y_prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33a8474a-31d6-40d1-ed28-40f1e8c7d1f4",
        "id": "9mFj8pSm2cFS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[142   0]\n",
            " [  1 607]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (metrics.precision_score( Y_valid_scaled['label_3'],y_prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a305aaa1-0087-4a78-b8bb-a73d8e3614c0",
        "id": "Ze7G5Z6O2cFT"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (metrics.accuracy_score( Y_valid_scaled['label_3'] ,y_prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7e6fcad-18d9-4217-a396-eac0a6f694ce",
        "id": "O89s0hTy2cFT"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9986666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (metrics.recall_score( Y_valid_scaled['label_3'] ,y_prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac77aaf5-35ef-4f13-face-3f945999ff83",
        "id": "BMUnSF6q2cFT"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9983552631578947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Applying Feature Selection Techniques"
      ],
      "metadata": {
        "id": "Qv4ZbIIx2cFT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Univariate feature selection\n",
        "\n",
        "Univariate feature selection works by selecting the best features based on univariate statistical tests. It can be seen as a preprocessing step to an estimator."
      ],
      "metadata": {
        "id": "UAcqcdhU2cFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest,f_classif\n",
        "selector = SelectKBest(f_classif,k=10)\n",
        "X_new_f1 = selector.fit_transform(X_train_scaled['label_3'],Y_train_scaled['label_3'])\n",
        "print ('New Shape according to the feature selection technique 1', X_new_f1.shape )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bb3ec66-c4d7-4808-96cf-14a956366812",
        "id": "NxQyZcv92cFU"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Shape according to the feature selection technique 1 (28520, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then try to train the model with new feature count and see the difference.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mo6Cxje82cFU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classification=svm.SVC(kernel='linear')\n",
        "classification.fit(X_new_f1,Y_train_scaled['label_3'])\n",
        "y_prediction = classification.predict(selector.transform(X_valid_scaled['label_3']))\n",
        "y_test_prediction = classification.predict(selector.transform(X_test_scaled['label_3']))\n",
        "print(y_test_prediction)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XVPszjUn2cFU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1826464-3739-415e-95c5-4ea40b453590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
            " 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1\n",
            " 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.confusion_matrix( Y_valid_scaled['label_3'] ,y_prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a109414-12e6-40c0-a6c8-5d22a12cd8a8",
        "id": "ijleQSFq2cFU"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[137   5]\n",
            " [ 10 598]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (metrics.precision_score( Y_valid_scaled['label_3'] ,y_prediction,average='weighted'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82cc69cc-7795-4c05-8437-9d51b8083a4d",
        "id": "1D2Z3OHV2cFU"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9774185666185666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (metrics.accuracy_score( Y_valid_scaled['label_3'] ,y_prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d24f7b08-8319-4f09-a95e-73f234f20ad2",
        "id": "C6Ex2uD82cFV"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (metrics.recall_score( Y_valid_scaled['label_3'] ,y_prediction,average='weighted'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "682ea33a-7428-4bfc-90eb-53c3924eecaf",
        "id": "pLov_UIR2cFV"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('precision: ',metrics.precision_score( Y_valid_scaled['label_3'] ,y_prediction,average='weighted'))\n",
        "print('accuracy: ',metrics.accuracy_score( Y_valid_scaled['label_3'] ,y_prediction))\n",
        "print('recall: ',metrics.recall_score( Y_valid_scaled['label_3'] ,y_prediction,average='weighted'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWCDygKFAAwu",
        "outputId": "e9dadf37-acf5-48a0-e20f-97c0d5f9bd0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision:  0.9803982355794724\n",
            "accuracy:  0.98\n",
            "recall:  0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to this feature selection method  to streamline model managed to reduce the feature count from 256 to 5 and 25\n"
      ],
      "metadata": {
        "id": "1FugheUr2cFV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### sklearn.decomposition.PCA"
      ],
      "metadata": {
        "id": "gWTMRxlWezp9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear dimensionality reduction using Singular Value Decomposition of the data to project it to a lower dimensional space. The input data is centered but not scaled for each feature before applying the SVD."
      ],
      "metadata": {
        "id": "IxHyDJ_pezp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=0.40,svd_solver='full')\n",
        "pca.fit(X_train_scaled['label_1'])\n",
        "x_train_transformation= pd.DataFrame(pca.transform(X_train_scaled['label_3']))\n",
        "x_valid_transformation= pd.DataFrame(pca.transform(X_valid_scaled['label_3']))\n",
        "x_test_transformation= pd.DataFrame(pca.transform(X_test_scaled['label_3']))\n",
        "x_test_transformation_pass= pca.transform(X_test_scaled['label_3'])\n",
        "print ('New Shape according to the feature selection technique 1', x_train_transformation.shape )\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12f4ae29-6d78-4f3f-c693-c7d2097b3466",
        "id": "1_lLCrI6ezqA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Shape according to the feature selection technique 1 (28520, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then try to train the model with new feature count and see the difference."
      ],
      "metadata": {
        "id": "b3NHsPkdezqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classification=svm.SVC(kernel='linear')\n",
        "classification.fit(x_train_transformation,Y_train_scaled['label_3'])\n",
        "y_prediction = classification.predict(x_valid_transformation)\n",
        "y_pred_test_after = classification.predict(x_test_transformation)\n",
        "print('Predicted labels after feature engineering:', y_pred_test_after)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "375367e5-6b3b-4b9b-c707-a84541eea289",
        "id": "skpCtJ0xezqC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted labels after feature engineering: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
            " 0 0 1 0 0 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 1 1 1 1 1 1 0 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 1 1\n",
            " 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.confusion_matrix( Y_valid_scaled['label_3'] ,y_prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a8c2fd9-2f95-4073-8826-d45c391d6550",
        "id": "i5HD55vwezqD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[128  14]\n",
            " [  9 599]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (metrics.precision_score( Y_valid_scaled['label_3'] ,y_prediction,average='weighted'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4978c0a-f287-4d4b-8faa-b0043a8ad7b7",
        "id": "T4Vsy1WmezqD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9620553181192202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (metrics.accuracy_score( Y_valid_scaled['label_3'] ,y_prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af742536-ac9b-46b1-e5d4-702ccc431b16",
        "id": "tTXb5NxHezqE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9605978260869565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (metrics.recall_score( Y_valid_scaled['label_3'] ,y_prediction,average='weighted'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "904df03b-560a-43d8-8ed1-491738917472",
        "id": "juNa2XXTezqE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9605978260869565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"precision\",metrics.precision_score( Y_valid_scaled['label_3'] ,y_prediction,average='weighted'))\n",
        "print (\"accuracy\",metrics.accuracy_score( Y_valid_scaled['label_3'] ,y_prediction))\n",
        "print (\"recall\",metrics.recall_score( Y_valid_scaled['label_3'] ,y_prediction,average='weighted'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00e18255-c483-4d0f-db3c-af4418a95946",
        "id": "L4OUupSxezqE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision 0.9690476337901827\n",
            "accuracy 0.9693333333333334\n",
            "recall 0.9693333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_df = pd.DataFrame({\n",
        "    'Predicted labels before feature engineering': y_pred_test_before,\n",
        "    'Predicted labels after feature engineering': y_pred_test_after,\n",
        "    'No. of new features': x_test_transformation_pass.shape[1]\n",
        "})\n",
        "\n",
        "\n",
        "for i in range(x_test_transformation_pass.shape[1]):\n",
        "  output_df[f'New feature {i+1}'] = x_test_transformation_pass[:, i]\n",
        "\n",
        "output_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "RzhMaJugezqE",
        "outputId": "71755743-087c-4af9-c0f8-75ac65d861b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Predicted labels before feature engineering  \\\n",
              "0                                            1   \n",
              "1                                            1   \n",
              "2                                            1   \n",
              "3                                            1   \n",
              "4                                            1   \n",
              "\n",
              "   Predicted labels after feature engineering  No. of new features  \\\n",
              "0                                           1                   49   \n",
              "1                                           1                   49   \n",
              "2                                           1                   49   \n",
              "3                                           1                   49   \n",
              "4                                           1                   49   \n",
              "\n",
              "   New feature 1  New feature 2  New feature 3  New feature 4  New feature 5  \\\n",
              "0      -2.031041       7.072996      -3.899170      -1.139218      -6.607480   \n",
              "1      -6.757219       9.020226      -0.445499     -10.395753      -4.692880   \n",
              "2      -4.869828       3.637857      -0.251019      -5.658368      -2.325319   \n",
              "3      -2.185382       6.080549      -1.050191      -0.983411       2.460842   \n",
              "4       0.699202       6.304911       1.514615      -3.189496      -2.997243   \n",
              "\n",
              "   New feature 6  New feature 7  New feature 8  New feature 9  New feature 10  \\\n",
              "0      -1.029961       3.773949       2.677365       6.098684        1.982514   \n",
              "1       2.287994      -1.798454       2.344746      -2.620985        7.354878   \n",
              "2      -1.254303      -0.189561      -0.317199      -5.770944        4.860928   \n",
              "3       4.478364       0.687827       0.340539       1.508543        6.158429   \n",
              "4      -1.164269       1.858609       3.491644       0.830667        7.437580   \n",
              "\n",
              "   New feature 11  New feature 12  New feature 13  New feature 14  \\\n",
              "0        4.271610       -0.406518       -0.540450       -3.835481   \n",
              "1       -0.439397       -1.280962       -2.865353       -0.332620   \n",
              "2        2.908031       -0.782643       -1.435120       -3.528007   \n",
              "3        3.231875        3.770242        2.019773       -3.831132   \n",
              "4       -0.771613        1.720614        0.374078       -1.453283   \n",
              "\n",
              "   New feature 15  New feature 16  New feature 17  New feature 18  \\\n",
              "0        0.779858       -2.234409        0.416891        1.855999   \n",
              "1       -3.267785        3.044503       -2.110337       -2.286687   \n",
              "2       -1.247274        1.017284        2.006186        0.131780   \n",
              "3        1.881271        1.483123       -2.009631       -2.891516   \n",
              "4        0.912510       -1.763192       -1.246238        0.292901   \n",
              "\n",
              "   New feature 19  New feature 20  New feature 21  New feature 22  \\\n",
              "0       -2.593841       -0.777323       -1.372895        1.763319   \n",
              "1       -1.466394       -1.599279        0.393073        3.609559   \n",
              "2       -1.293697       -2.652614       -0.442117        3.247119   \n",
              "3        3.055495       -2.692857       -0.153073        1.404473   \n",
              "4       -1.563358       -0.790820       -1.679885        4.156949   \n",
              "\n",
              "   New feature 23  New feature 24  New feature 25  New feature 26  \\\n",
              "0       -0.558357       -3.118723       -2.326503        0.724986   \n",
              "1       -0.204600       -2.513195       -2.702389        1.877266   \n",
              "2        0.056819       -5.288655       -1.799017        0.439549   \n",
              "3       -0.204970       -6.016035        0.011836       -1.896885   \n",
              "4        0.301556        0.254043        1.128256        1.104217   \n",
              "\n",
              "   New feature 27  New feature 28  New feature 29  New feature 30  \\\n",
              "0        1.451095       -1.011355       -2.530412        1.979696   \n",
              "1       -2.680341        0.495570        0.172885        0.224661   \n",
              "2       -2.490127        1.684036        0.167060        1.223364   \n",
              "3        0.218005        1.522549       -2.892885        1.143720   \n",
              "4       -0.827386        0.686154        1.817153        2.380075   \n",
              "\n",
              "   New feature 31  New feature 32  New feature 33  New feature 34  \\\n",
              "0        1.353403        0.300167        2.737875        2.935505   \n",
              "1        0.945643        0.240523       -0.889786        0.383714   \n",
              "2        2.511806       -0.065658       -0.749571       -1.029651   \n",
              "3        1.264005       -1.138008       -2.420727       -2.088253   \n",
              "4       -0.552908        0.795972       -1.427992        0.447777   \n",
              "\n",
              "   New feature 35  New feature 36  New feature 37  New feature 38  \\\n",
              "0       -0.935346       -1.454484       -0.471733        2.441985   \n",
              "1       -0.602832       -1.553723       -1.209518        0.948211   \n",
              "2       -1.081592       -1.382162       -0.782291        0.076146   \n",
              "3       -1.291993       -0.584451       -2.098503        0.148559   \n",
              "4       -0.112454       -0.795440       -1.952042        0.524060   \n",
              "\n",
              "   New feature 39  New feature 40  New feature 41  New feature 42  \\\n",
              "0       -1.187771       -0.387655       -0.386766        0.573784   \n",
              "1       -0.729147       -0.962219       -0.775931       -1.569257   \n",
              "2        0.992883       -0.258094       -0.705611        0.900671   \n",
              "3        1.161322       -2.600385        0.400560        0.977827   \n",
              "4        0.007208        2.851649        0.776596        0.756446   \n",
              "\n",
              "   New feature 43  New feature 44  New feature 45  New feature 46  \\\n",
              "0        2.539350       -0.666926        1.650883       -0.689341   \n",
              "1        0.893573        0.399989       -0.748271        0.128024   \n",
              "2        0.309704        1.042084       -1.556142       -0.251696   \n",
              "3       -0.855402       -0.446161       -1.031986        0.232316   \n",
              "4       -0.818649       -2.182648       -0.238775       -1.197995   \n",
              "\n",
              "   New feature 47  New feature 48  New feature 49  \n",
              "0       -0.584489       -0.285500        0.766816  \n",
              "1       -0.401761        0.173239        1.512876  \n",
              "2        0.544656        1.702426       -0.604844  \n",
              "3        0.411214       -1.096601        0.987214  \n",
              "4        0.959438       -0.099103       -0.657507  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a5df894f-75b0-45bc-a8d8-01bfe0a1055c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted labels before feature engineering</th>\n",
              "      <th>Predicted labels after feature engineering</th>\n",
              "      <th>No. of new features</th>\n",
              "      <th>New feature 1</th>\n",
              "      <th>New feature 2</th>\n",
              "      <th>New feature 3</th>\n",
              "      <th>New feature 4</th>\n",
              "      <th>New feature 5</th>\n",
              "      <th>New feature 6</th>\n",
              "      <th>New feature 7</th>\n",
              "      <th>New feature 8</th>\n",
              "      <th>New feature 9</th>\n",
              "      <th>New feature 10</th>\n",
              "      <th>New feature 11</th>\n",
              "      <th>New feature 12</th>\n",
              "      <th>New feature 13</th>\n",
              "      <th>New feature 14</th>\n",
              "      <th>New feature 15</th>\n",
              "      <th>New feature 16</th>\n",
              "      <th>New feature 17</th>\n",
              "      <th>New feature 18</th>\n",
              "      <th>New feature 19</th>\n",
              "      <th>New feature 20</th>\n",
              "      <th>New feature 21</th>\n",
              "      <th>New feature 22</th>\n",
              "      <th>New feature 23</th>\n",
              "      <th>New feature 24</th>\n",
              "      <th>New feature 25</th>\n",
              "      <th>New feature 26</th>\n",
              "      <th>New feature 27</th>\n",
              "      <th>New feature 28</th>\n",
              "      <th>New feature 29</th>\n",
              "      <th>New feature 30</th>\n",
              "      <th>New feature 31</th>\n",
              "      <th>New feature 32</th>\n",
              "      <th>New feature 33</th>\n",
              "      <th>New feature 34</th>\n",
              "      <th>New feature 35</th>\n",
              "      <th>New feature 36</th>\n",
              "      <th>New feature 37</th>\n",
              "      <th>New feature 38</th>\n",
              "      <th>New feature 39</th>\n",
              "      <th>New feature 40</th>\n",
              "      <th>New feature 41</th>\n",
              "      <th>New feature 42</th>\n",
              "      <th>New feature 43</th>\n",
              "      <th>New feature 44</th>\n",
              "      <th>New feature 45</th>\n",
              "      <th>New feature 46</th>\n",
              "      <th>New feature 47</th>\n",
              "      <th>New feature 48</th>\n",
              "      <th>New feature 49</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>49</td>\n",
              "      <td>-2.031041</td>\n",
              "      <td>7.072996</td>\n",
              "      <td>-3.899170</td>\n",
              "      <td>-1.139218</td>\n",
              "      <td>-6.607480</td>\n",
              "      <td>-1.029961</td>\n",
              "      <td>3.773949</td>\n",
              "      <td>2.677365</td>\n",
              "      <td>6.098684</td>\n",
              "      <td>1.982514</td>\n",
              "      <td>4.271610</td>\n",
              "      <td>-0.406518</td>\n",
              "      <td>-0.540450</td>\n",
              "      <td>-3.835481</td>\n",
              "      <td>0.779858</td>\n",
              "      <td>-2.234409</td>\n",
              "      <td>0.416891</td>\n",
              "      <td>1.855999</td>\n",
              "      <td>-2.593841</td>\n",
              "      <td>-0.777323</td>\n",
              "      <td>-1.372895</td>\n",
              "      <td>1.763319</td>\n",
              "      <td>-0.558357</td>\n",
              "      <td>-3.118723</td>\n",
              "      <td>-2.326503</td>\n",
              "      <td>0.724986</td>\n",
              "      <td>1.451095</td>\n",
              "      <td>-1.011355</td>\n",
              "      <td>-2.530412</td>\n",
              "      <td>1.979696</td>\n",
              "      <td>1.353403</td>\n",
              "      <td>0.300167</td>\n",
              "      <td>2.737875</td>\n",
              "      <td>2.935505</td>\n",
              "      <td>-0.935346</td>\n",
              "      <td>-1.454484</td>\n",
              "      <td>-0.471733</td>\n",
              "      <td>2.441985</td>\n",
              "      <td>-1.187771</td>\n",
              "      <td>-0.387655</td>\n",
              "      <td>-0.386766</td>\n",
              "      <td>0.573784</td>\n",
              "      <td>2.539350</td>\n",
              "      <td>-0.666926</td>\n",
              "      <td>1.650883</td>\n",
              "      <td>-0.689341</td>\n",
              "      <td>-0.584489</td>\n",
              "      <td>-0.285500</td>\n",
              "      <td>0.766816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>49</td>\n",
              "      <td>-6.757219</td>\n",
              "      <td>9.020226</td>\n",
              "      <td>-0.445499</td>\n",
              "      <td>-10.395753</td>\n",
              "      <td>-4.692880</td>\n",
              "      <td>2.287994</td>\n",
              "      <td>-1.798454</td>\n",
              "      <td>2.344746</td>\n",
              "      <td>-2.620985</td>\n",
              "      <td>7.354878</td>\n",
              "      <td>-0.439397</td>\n",
              "      <td>-1.280962</td>\n",
              "      <td>-2.865353</td>\n",
              "      <td>-0.332620</td>\n",
              "      <td>-3.267785</td>\n",
              "      <td>3.044503</td>\n",
              "      <td>-2.110337</td>\n",
              "      <td>-2.286687</td>\n",
              "      <td>-1.466394</td>\n",
              "      <td>-1.599279</td>\n",
              "      <td>0.393073</td>\n",
              "      <td>3.609559</td>\n",
              "      <td>-0.204600</td>\n",
              "      <td>-2.513195</td>\n",
              "      <td>-2.702389</td>\n",
              "      <td>1.877266</td>\n",
              "      <td>-2.680341</td>\n",
              "      <td>0.495570</td>\n",
              "      <td>0.172885</td>\n",
              "      <td>0.224661</td>\n",
              "      <td>0.945643</td>\n",
              "      <td>0.240523</td>\n",
              "      <td>-0.889786</td>\n",
              "      <td>0.383714</td>\n",
              "      <td>-0.602832</td>\n",
              "      <td>-1.553723</td>\n",
              "      <td>-1.209518</td>\n",
              "      <td>0.948211</td>\n",
              "      <td>-0.729147</td>\n",
              "      <td>-0.962219</td>\n",
              "      <td>-0.775931</td>\n",
              "      <td>-1.569257</td>\n",
              "      <td>0.893573</td>\n",
              "      <td>0.399989</td>\n",
              "      <td>-0.748271</td>\n",
              "      <td>0.128024</td>\n",
              "      <td>-0.401761</td>\n",
              "      <td>0.173239</td>\n",
              "      <td>1.512876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>49</td>\n",
              "      <td>-4.869828</td>\n",
              "      <td>3.637857</td>\n",
              "      <td>-0.251019</td>\n",
              "      <td>-5.658368</td>\n",
              "      <td>-2.325319</td>\n",
              "      <td>-1.254303</td>\n",
              "      <td>-0.189561</td>\n",
              "      <td>-0.317199</td>\n",
              "      <td>-5.770944</td>\n",
              "      <td>4.860928</td>\n",
              "      <td>2.908031</td>\n",
              "      <td>-0.782643</td>\n",
              "      <td>-1.435120</td>\n",
              "      <td>-3.528007</td>\n",
              "      <td>-1.247274</td>\n",
              "      <td>1.017284</td>\n",
              "      <td>2.006186</td>\n",
              "      <td>0.131780</td>\n",
              "      <td>-1.293697</td>\n",
              "      <td>-2.652614</td>\n",
              "      <td>-0.442117</td>\n",
              "      <td>3.247119</td>\n",
              "      <td>0.056819</td>\n",
              "      <td>-5.288655</td>\n",
              "      <td>-1.799017</td>\n",
              "      <td>0.439549</td>\n",
              "      <td>-2.490127</td>\n",
              "      <td>1.684036</td>\n",
              "      <td>0.167060</td>\n",
              "      <td>1.223364</td>\n",
              "      <td>2.511806</td>\n",
              "      <td>-0.065658</td>\n",
              "      <td>-0.749571</td>\n",
              "      <td>-1.029651</td>\n",
              "      <td>-1.081592</td>\n",
              "      <td>-1.382162</td>\n",
              "      <td>-0.782291</td>\n",
              "      <td>0.076146</td>\n",
              "      <td>0.992883</td>\n",
              "      <td>-0.258094</td>\n",
              "      <td>-0.705611</td>\n",
              "      <td>0.900671</td>\n",
              "      <td>0.309704</td>\n",
              "      <td>1.042084</td>\n",
              "      <td>-1.556142</td>\n",
              "      <td>-0.251696</td>\n",
              "      <td>0.544656</td>\n",
              "      <td>1.702426</td>\n",
              "      <td>-0.604844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>49</td>\n",
              "      <td>-2.185382</td>\n",
              "      <td>6.080549</td>\n",
              "      <td>-1.050191</td>\n",
              "      <td>-0.983411</td>\n",
              "      <td>2.460842</td>\n",
              "      <td>4.478364</td>\n",
              "      <td>0.687827</td>\n",
              "      <td>0.340539</td>\n",
              "      <td>1.508543</td>\n",
              "      <td>6.158429</td>\n",
              "      <td>3.231875</td>\n",
              "      <td>3.770242</td>\n",
              "      <td>2.019773</td>\n",
              "      <td>-3.831132</td>\n",
              "      <td>1.881271</td>\n",
              "      <td>1.483123</td>\n",
              "      <td>-2.009631</td>\n",
              "      <td>-2.891516</td>\n",
              "      <td>3.055495</td>\n",
              "      <td>-2.692857</td>\n",
              "      <td>-0.153073</td>\n",
              "      <td>1.404473</td>\n",
              "      <td>-0.204970</td>\n",
              "      <td>-6.016035</td>\n",
              "      <td>0.011836</td>\n",
              "      <td>-1.896885</td>\n",
              "      <td>0.218005</td>\n",
              "      <td>1.522549</td>\n",
              "      <td>-2.892885</td>\n",
              "      <td>1.143720</td>\n",
              "      <td>1.264005</td>\n",
              "      <td>-1.138008</td>\n",
              "      <td>-2.420727</td>\n",
              "      <td>-2.088253</td>\n",
              "      <td>-1.291993</td>\n",
              "      <td>-0.584451</td>\n",
              "      <td>-2.098503</td>\n",
              "      <td>0.148559</td>\n",
              "      <td>1.161322</td>\n",
              "      <td>-2.600385</td>\n",
              "      <td>0.400560</td>\n",
              "      <td>0.977827</td>\n",
              "      <td>-0.855402</td>\n",
              "      <td>-0.446161</td>\n",
              "      <td>-1.031986</td>\n",
              "      <td>0.232316</td>\n",
              "      <td>0.411214</td>\n",
              "      <td>-1.096601</td>\n",
              "      <td>0.987214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>49</td>\n",
              "      <td>0.699202</td>\n",
              "      <td>6.304911</td>\n",
              "      <td>1.514615</td>\n",
              "      <td>-3.189496</td>\n",
              "      <td>-2.997243</td>\n",
              "      <td>-1.164269</td>\n",
              "      <td>1.858609</td>\n",
              "      <td>3.491644</td>\n",
              "      <td>0.830667</td>\n",
              "      <td>7.437580</td>\n",
              "      <td>-0.771613</td>\n",
              "      <td>1.720614</td>\n",
              "      <td>0.374078</td>\n",
              "      <td>-1.453283</td>\n",
              "      <td>0.912510</td>\n",
              "      <td>-1.763192</td>\n",
              "      <td>-1.246238</td>\n",
              "      <td>0.292901</td>\n",
              "      <td>-1.563358</td>\n",
              "      <td>-0.790820</td>\n",
              "      <td>-1.679885</td>\n",
              "      <td>4.156949</td>\n",
              "      <td>0.301556</td>\n",
              "      <td>0.254043</td>\n",
              "      <td>1.128256</td>\n",
              "      <td>1.104217</td>\n",
              "      <td>-0.827386</td>\n",
              "      <td>0.686154</td>\n",
              "      <td>1.817153</td>\n",
              "      <td>2.380075</td>\n",
              "      <td>-0.552908</td>\n",
              "      <td>0.795972</td>\n",
              "      <td>-1.427992</td>\n",
              "      <td>0.447777</td>\n",
              "      <td>-0.112454</td>\n",
              "      <td>-0.795440</td>\n",
              "      <td>-1.952042</td>\n",
              "      <td>0.524060</td>\n",
              "      <td>0.007208</td>\n",
              "      <td>2.851649</td>\n",
              "      <td>0.776596</td>\n",
              "      <td>0.756446</td>\n",
              "      <td>-0.818649</td>\n",
              "      <td>-2.182648</td>\n",
              "      <td>-0.238775</td>\n",
              "      <td>-1.197995</td>\n",
              "      <td>0.959438</td>\n",
              "      <td>-0.099103</td>\n",
              "      <td>-0.657507</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a5df894f-75b0-45bc-a8d8-01bfe0a1055c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a5df894f-75b0-45bc-a8d8-01bfe0a1055c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a5df894f-75b0-45bc-a8d8-01bfe0a1055c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-111c139f-c5f7-4067-93a8-f0ea80760620\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-111c139f-c5f7-4067-93a8-f0ea80760620')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-111c139f-c5f7-4067-93a8-f0ea80760620 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_df.to_csv(f\"190282X_label_3.csv\", index=False)"
      ],
      "metadata": {
        "id": "KoWwYU2lezqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7yD1FhlgezqF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Label 4"
      ],
      "metadata": {
        "id": "AyIxZJMF0tTx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training"
      ],
      "metadata": {
        "id": "RDL23ikD0tT0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "# Create a KNN classifier\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=5)  # You can adjust the number of neighbors (k) as needed\n",
        "\n",
        "# Fit the KNN classifier to the training data\n",
        "knn_classifier.fit(X_train_scaled['label_4'], Y_train_scaled['label_4'])\n",
        "\n",
        "# Make predictions using the KNN classifier\n",
        "y_prediction = knn_classifier.predict(X_valid_scaled['label_4'])\n",
        "y_pred_test_before = knn_classifier.predict(X_test_scaled['label_4'])\n",
        "print('Predicted labels before feature engineering:', y_pred_test_before)\n",
        "\n"
      ],
      "metadata": {
        "id": "quRlag8-0tT0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc1a48a1-6657-47b3-b54a-08b8f88ee116"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted labels before feature engineering: [ 6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6 13 13 13 13 13 13\n",
            " 13 13  4  4  4  4  4  4  4  4  4  4  4  4  6  4  4  4  6  6  6  6  6  6\n",
            "  6  6  6  6  6  6  5  5  5  5  5  5  5  5  5  5  5  1  1  1  1  1  1  1\n",
            "  1  1  1  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  2  2  2  2  2  2  2  2\n",
            "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "  6  6  6  5  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "  6  6  6  6  6  6  6  7  7  7  7  7  7  7  7  7  7  7  7 12  7  7  7  7\n",
            "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  3  3  3  3  3  3\n",
            "  3  3  3  3  3  3  3  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "  6  6  6  6  6  6  6  6  6  6  6  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            " 12 12 12 12 12 12 12 12 12 12 12 12 12  6  6  6  6  6  6  6  6  6  6  6\n",
            "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "  6  6  6  6  6  6  6  6  6  6  6  6 12 12 12 12 12 12  6  9  9  9  9  9\n",
            "  9  9  9  9  9  9  9  2  2  2  2  2  2  6  6  6  6  6  6  6  6  6  6  6\n",
            "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  8  8  8  8  8  8  8\n",
            "  8  8  8  8  8  8  8  8  8  6  6  6  6  6  6  6  6  6  6 11 11 11 11 11\n",
            " 11 11 11 11  6  6  6  6  6  6  6  6  6  6  6  7  7  7  7  7  7  7  7  7\n",
            "  7  7  7  7  7  0  0  0  0  0  0  0  0  0  2  2  2  2  2  2  2  2  2  2\n",
            " 10 10 10 10 10 10 10 10 10 10  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "  6  6  6  6  6  6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3X7ulALM0tT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.confusion_matrix( Y_valid_scaled['label_4'] ,y_prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e8125be-1592-42ab-bdd8-022fb70734cb",
        "id": "J5g5UEQ90tT1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 21   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0  11   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0  27   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   8   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0  15   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0  10   1   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 532   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   1  31   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   1   0  18   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  17   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  10   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  11   0   0]\n",
            " [  0   0   0   0   0   0   1   0   0   0   0   0  25   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  10]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (metrics.precision_score( Y_valid_scaled['label_4'] ,y_prediction,average='weighted'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed94a875-17d9-46fb-b44f-5b46f9e7f534",
        "id": "Jmw5OmCF0tT2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9947064676616915\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (metrics.accuracy_score( Y_valid_scaled['label_4'] ,y_prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e22ba2e-407d-4f45-afb4-a4c202b06db7",
        "id": "NQ34mAMm0tT2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9946666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (metrics.recall_score( Y_valid_scaled['label_4'] ,y_prediction,average='weighted'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f15b05aa-c802-4cdc-fefb-8274425f48b6",
        "id": "rfcJ1SVQ0tT3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9946666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Applying Feature Selection Techniques"
      ],
      "metadata": {
        "id": "T_Uoeyyf0tT3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### sklearn.decomposition.PCA"
      ],
      "metadata": {
        "id": "Yz2fCzW80tT6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear dimensionality reduction using Singular Value Decomposition of the data to project it to a lower dimensional space. The input data is centered but not scaled for each feature before applying the SVD."
      ],
      "metadata": {
        "id": "qJGx69bp0tT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=0.70,svd_solver='full')\n",
        "pca.fit(X_train_scaled['label_4'])\n",
        "x_train_transformation= pd.DataFrame(pca.transform(X_train_scaled['label_4']))\n",
        "x_valid_transformation= pd.DataFrame(pca.transform(X_valid_scaled['label_4']))\n",
        "x_test_transformation= pca.transform(X_test_scaled['label_4'])\n",
        "\n",
        "\n",
        "print ('New Shape according to the feature selection technique 1', x_train_transformation.shape )\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6b15519-f79a-44e4-d8a7-ed7c80a7b0e5",
        "id": "Ni9a6l9m0tT7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Shape according to the feature selection technique 1 (28520, 21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then try to train the model with new feature count and see the difference."
      ],
      "metadata": {
        "id": "LUAl3xQI0tT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "\n",
        "# Create a KNN classifier\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=5)  # You can adjust the number of neighbors (k) as needed\n",
        "\n",
        "# Fit the KNN classifier to the training data\n",
        "knn_classifier.fit(x_train_transformation, Y_train_scaled['label_4'])\n",
        "\n",
        "# Make predictions using the KNN classifier\n",
        "y_prediction = knn_classifier.predict(x_valid_transformation)\n",
        "y_pred_test_after = knn_classifier.predict(x_test_transformation)\n",
        "print('Predicted labels after feature engineering:', y_pred_test_after)\n"
      ],
      "metadata": {
        "id": "zygwKfH60tT7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe896ace-a4e4-4be3-becc-b659c926ca17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted labels after feature engineering: [ 6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6 13 13 13 13 13 13\n",
            " 13 13  4  4  4  4  4  6  4  4  1  4  4  4  4  6  4  4  6  6  6  6  6  6\n",
            "  6  6  6  6  6  6  5  5  5  5  5  5  5  5  5  5  5  1  1  1  1  1  1  1\n",
            "  1  1  1  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "  6  6  6  6  2  6  6  6  6  6  6  6  6  6  6  6  2  2  2  2  2  6  2  2\n",
            "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "  6  6  6  5  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "  6  6  6  6  6  6  6  7  7  7  7  6  7  7  7  7  7  7  7 12  7  7  7  7\n",
            "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  3  3  3  3  3  3\n",
            "  3  3  3  3  3  3  3  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "  6  6  6  6  6  6  6  6  6  6  6  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            " 12 12  7 12 12 12 12 12 12 12 12 12 12  6  6  6  6  6  6  6  6  6  6  6\n",
            "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "  6  6  6  6  6  6  6  6  6  6  6  6 12 12  6 12 12 12  8  9  9  9  9  9\n",
            "  9  9  9  9  9  9  9  2  2  2  2  2  2  6  6  6  6  6  6  6  6  6  6  6\n",
            "  6  6  6  6  6  6  6  1  6  6  6  6  6  6  6  6  6  8  8  8  8  8  8  8\n",
            "  8  8  8  6  8  8  8  8  8  6  6  6  6  6  6  6  6  6  6 11 11 11 11 11\n",
            " 11 11 11 11  6  6  6  6  6  6  6  6  6  6  6  7  7  7  7  7  7  7  7  7\n",
            "  7  7  7  7  7  6  0  0  6  0  0  0  0  0  2  2  2  2  2  2  2  2  2  2\n",
            " 10 10 10 10 10 10 10 10 10 10  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "  6  6  6  6  6  6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.confusion_matrix( Y_valid_scaled['label_4'] ,y_prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69cbf1c5-fdf9-4712-8767-3b73bbe4a3f5",
        "id": "PnOB2Fmr0tT7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 19   0   0   0   0   0   2   0   0   0   0   0   0   0]\n",
            " [  0   9   0   0   0   0   1   1   0   0   0   0   0   0]\n",
            " [  0   0  27   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   8   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0  14   0   1   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0  10   1   0   0   0   0   0   0   0]\n",
            " [  4   0   4   0   0   0 523   1   0   0   0   0   0   0]\n",
            " [  1   0   0   0   1   0   0  30   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   3   0  16   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   1   0   0  16   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  10   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  11   0   0]\n",
            " [  0   0   0   0   0   0   3   0   0   0   0   0  23   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  10]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (metrics.precision_score( Y_valid_scaled['label_4'] ,y_prediction,average='weighted'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "feb02930-e083-47e3-9195-a70cdf8b8958",
        "id": "9A0Weutp0tT8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9766319451841071\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (metrics.accuracy_score( Y_valid_scaled['label_4'] ,y_prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9628acc0-64a4-49e7-89b4-1d45d4c7adf9",
        "id": "6LYkBWYL0tT8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.976\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (metrics.recall_score( Y_valid_scaled['label_4'] ,y_prediction,average='weighted'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a89b9c11-7568-4320-a193-39e5bab11fff",
        "id": "WTV8-YlW0tT8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.976\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('precision: ',metrics.precision_score( Y_valid_scaled['label_4'] ,y_prediction,average='weighted'))\n",
        "print('accuracy: ',metrics.accuracy_score( Y_valid_scaled['label_4'] ,y_prediction))\n",
        "print('recall: ',metrics.recall_score( Y_valid_scaled['label_4'] ,y_prediction,average='weighted'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DY0_DyENAYKh",
        "outputId": "e3f0bb72-b07a-403a-d6ca-e2a803a1b218"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision:  0.9696112250025123\n",
            "accuracy:  0.968\n",
            "recall:  0.968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_df = pd.DataFrame({\n",
        "    'Predicted labels before feature engineering': y_pred_test_before,\n",
        "    'Predicted labels after feature engineering': y_pred_test_after,\n",
        "    'No. of new features': x_test_transformation.shape[1]\n",
        "})\n",
        "\n",
        "\n",
        "for i in range(x_test_transformation.shape[1]):\n",
        "  output_df[f'New feature {i+1}'] = x_test_transformation[:, i]\n",
        "\n",
        "output_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "SNviG0EnmgoJ",
        "outputId": "b9e59d7b-d24d-46fd-f955-85f9f9a34c7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Predicted labels before feature engineering  \\\n",
              "0                                            6   \n",
              "1                                            6   \n",
              "2                                            6   \n",
              "3                                            6   \n",
              "4                                            6   \n",
              "\n",
              "   Predicted labels after feature engineering  No. of new features  \\\n",
              "0                                           6                   21   \n",
              "1                                           6                   21   \n",
              "2                                           6                   21   \n",
              "3                                           6                   21   \n",
              "4                                           6                   21   \n",
              "\n",
              "   New feature 1  New feature 2  New feature 3  New feature 4  New feature 5  \\\n",
              "0      -2.031041       7.072996      -3.899170      -1.139218      -6.607480   \n",
              "1      -6.757219       9.020226      -0.445499     -10.395753      -4.692880   \n",
              "2      -4.869828       3.637857      -0.251019      -5.658368      -2.325319   \n",
              "3      -2.185382       6.080549      -1.050191      -0.983411       2.460842   \n",
              "4       0.699202       6.304911       1.514615      -3.189496      -2.997243   \n",
              "\n",
              "   New feature 6  New feature 7  New feature 8  New feature 9  New feature 10  \\\n",
              "0      -1.029961       3.773949       2.677365       6.098684        1.982514   \n",
              "1       2.287994      -1.798454       2.344746      -2.620985        7.354878   \n",
              "2      -1.254303      -0.189561      -0.317199      -5.770944        4.860928   \n",
              "3       4.478364       0.687827       0.340539       1.508543        6.158429   \n",
              "4      -1.164269       1.858609       3.491644       0.830667        7.437580   \n",
              "\n",
              "   New feature 11  New feature 12  New feature 13  New feature 14  \\\n",
              "0        4.271610       -0.406518       -0.540450       -3.835481   \n",
              "1       -0.439397       -1.280962       -2.865353       -0.332620   \n",
              "2        2.908031       -0.782643       -1.435120       -3.528007   \n",
              "3        3.231875        3.770242        2.019773       -3.831132   \n",
              "4       -0.771613        1.720614        0.374078       -1.453283   \n",
              "\n",
              "   New feature 15  New feature 16  New feature 17  New feature 18  \\\n",
              "0        0.779858       -2.234409        0.416891        1.855999   \n",
              "1       -3.267785        3.044503       -2.110337       -2.286687   \n",
              "2       -1.247274        1.017284        2.006186        0.131780   \n",
              "3        1.881271        1.483123       -2.009631       -2.891516   \n",
              "4        0.912510       -1.763192       -1.246238        0.292901   \n",
              "\n",
              "   New feature 19  New feature 20  New feature 21  \n",
              "0       -2.593841       -0.777323       -1.372895  \n",
              "1       -1.466394       -1.599279        0.393073  \n",
              "2       -1.293697       -2.652614       -0.442117  \n",
              "3        3.055495       -2.692857       -0.153073  \n",
              "4       -1.563358       -0.790820       -1.679885  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ff141256-b9af-4d6f-8b1c-4cfc6797e971\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted labels before feature engineering</th>\n",
              "      <th>Predicted labels after feature engineering</th>\n",
              "      <th>No. of new features</th>\n",
              "      <th>New feature 1</th>\n",
              "      <th>New feature 2</th>\n",
              "      <th>New feature 3</th>\n",
              "      <th>New feature 4</th>\n",
              "      <th>New feature 5</th>\n",
              "      <th>New feature 6</th>\n",
              "      <th>New feature 7</th>\n",
              "      <th>New feature 8</th>\n",
              "      <th>New feature 9</th>\n",
              "      <th>New feature 10</th>\n",
              "      <th>New feature 11</th>\n",
              "      <th>New feature 12</th>\n",
              "      <th>New feature 13</th>\n",
              "      <th>New feature 14</th>\n",
              "      <th>New feature 15</th>\n",
              "      <th>New feature 16</th>\n",
              "      <th>New feature 17</th>\n",
              "      <th>New feature 18</th>\n",
              "      <th>New feature 19</th>\n",
              "      <th>New feature 20</th>\n",
              "      <th>New feature 21</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>21</td>\n",
              "      <td>-2.031041</td>\n",
              "      <td>7.072996</td>\n",
              "      <td>-3.899170</td>\n",
              "      <td>-1.139218</td>\n",
              "      <td>-6.607480</td>\n",
              "      <td>-1.029961</td>\n",
              "      <td>3.773949</td>\n",
              "      <td>2.677365</td>\n",
              "      <td>6.098684</td>\n",
              "      <td>1.982514</td>\n",
              "      <td>4.271610</td>\n",
              "      <td>-0.406518</td>\n",
              "      <td>-0.540450</td>\n",
              "      <td>-3.835481</td>\n",
              "      <td>0.779858</td>\n",
              "      <td>-2.234409</td>\n",
              "      <td>0.416891</td>\n",
              "      <td>1.855999</td>\n",
              "      <td>-2.593841</td>\n",
              "      <td>-0.777323</td>\n",
              "      <td>-1.372895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>21</td>\n",
              "      <td>-6.757219</td>\n",
              "      <td>9.020226</td>\n",
              "      <td>-0.445499</td>\n",
              "      <td>-10.395753</td>\n",
              "      <td>-4.692880</td>\n",
              "      <td>2.287994</td>\n",
              "      <td>-1.798454</td>\n",
              "      <td>2.344746</td>\n",
              "      <td>-2.620985</td>\n",
              "      <td>7.354878</td>\n",
              "      <td>-0.439397</td>\n",
              "      <td>-1.280962</td>\n",
              "      <td>-2.865353</td>\n",
              "      <td>-0.332620</td>\n",
              "      <td>-3.267785</td>\n",
              "      <td>3.044503</td>\n",
              "      <td>-2.110337</td>\n",
              "      <td>-2.286687</td>\n",
              "      <td>-1.466394</td>\n",
              "      <td>-1.599279</td>\n",
              "      <td>0.393073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>21</td>\n",
              "      <td>-4.869828</td>\n",
              "      <td>3.637857</td>\n",
              "      <td>-0.251019</td>\n",
              "      <td>-5.658368</td>\n",
              "      <td>-2.325319</td>\n",
              "      <td>-1.254303</td>\n",
              "      <td>-0.189561</td>\n",
              "      <td>-0.317199</td>\n",
              "      <td>-5.770944</td>\n",
              "      <td>4.860928</td>\n",
              "      <td>2.908031</td>\n",
              "      <td>-0.782643</td>\n",
              "      <td>-1.435120</td>\n",
              "      <td>-3.528007</td>\n",
              "      <td>-1.247274</td>\n",
              "      <td>1.017284</td>\n",
              "      <td>2.006186</td>\n",
              "      <td>0.131780</td>\n",
              "      <td>-1.293697</td>\n",
              "      <td>-2.652614</td>\n",
              "      <td>-0.442117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>21</td>\n",
              "      <td>-2.185382</td>\n",
              "      <td>6.080549</td>\n",
              "      <td>-1.050191</td>\n",
              "      <td>-0.983411</td>\n",
              "      <td>2.460842</td>\n",
              "      <td>4.478364</td>\n",
              "      <td>0.687827</td>\n",
              "      <td>0.340539</td>\n",
              "      <td>1.508543</td>\n",
              "      <td>6.158429</td>\n",
              "      <td>3.231875</td>\n",
              "      <td>3.770242</td>\n",
              "      <td>2.019773</td>\n",
              "      <td>-3.831132</td>\n",
              "      <td>1.881271</td>\n",
              "      <td>1.483123</td>\n",
              "      <td>-2.009631</td>\n",
              "      <td>-2.891516</td>\n",
              "      <td>3.055495</td>\n",
              "      <td>-2.692857</td>\n",
              "      <td>-0.153073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>21</td>\n",
              "      <td>0.699202</td>\n",
              "      <td>6.304911</td>\n",
              "      <td>1.514615</td>\n",
              "      <td>-3.189496</td>\n",
              "      <td>-2.997243</td>\n",
              "      <td>-1.164269</td>\n",
              "      <td>1.858609</td>\n",
              "      <td>3.491644</td>\n",
              "      <td>0.830667</td>\n",
              "      <td>7.437580</td>\n",
              "      <td>-0.771613</td>\n",
              "      <td>1.720614</td>\n",
              "      <td>0.374078</td>\n",
              "      <td>-1.453283</td>\n",
              "      <td>0.912510</td>\n",
              "      <td>-1.763192</td>\n",
              "      <td>-1.246238</td>\n",
              "      <td>0.292901</td>\n",
              "      <td>-1.563358</td>\n",
              "      <td>-0.790820</td>\n",
              "      <td>-1.679885</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff141256-b9af-4d6f-8b1c-4cfc6797e971')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ff141256-b9af-4d6f-8b1c-4cfc6797e971 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ff141256-b9af-4d6f-8b1c-4cfc6797e971');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0d83787e-6dfc-4687-b907-bc3c53beb711\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0d83787e-6dfc-4687-b907-bc3c53beb711')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0d83787e-6dfc-4687-b907-bc3c53beb711 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_df.to_csv(f\"190282X_label_4.csv\", index=False)"
      ],
      "metadata": {
        "id": "VoOjn1HJmmrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZAfhw73Y0tT8"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "dPcUX-eY0KPN"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMoZ3+4AUeER8K0zu8giozB",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}